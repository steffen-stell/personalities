{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: line 1: nvidia-smi: command not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA GPU found in your device\n",
      "Version 0.9.5 of metric_visualizer is outdated. Version 0.9.6 was released Monday March 06, 2023.\n",
      "[2023-03-23 11:18:00] (2.0.28) \u001b[31mPyABSA(2.0.28): \n",
      "[New Feature] Aspect Sentiment Triplet Extraction from v2.1.0 test version (https://github.com/yangheng95/PyABSA/tree/v2/examples-v2/aspect_sentiment_triplet_extration)\n",
      "[New Feature] Aspect CategoryOpinion Sentiment Quadruple Extraction from v2.2.0 test version (https://github.com/yangheng95/PyABSA/tree/v2/examples-v2/aspect_opinion_sentiment_category_extraction)\n",
      "\n",
      "If you find any problems, please report them on GitHub. Thanks!\n",
      "The v2.x versions are not compatible with Google Colab. Please downgrade to 1.16.27.\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pyabsa import AspectPolarityClassification as APC\n",
    "from pyabsa import ModelSaveOption, DeviceTypeOption\n",
    "from metric_visualizer import MetricVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steffen/.conda/envs/thesis/lib/python3.10/multiprocessing/pool.py:268: ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.Pool state=RUN pool_size=1>\n",
      "  _warn(f\"unclosed running multiprocessing pool {self!r}\",\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "config = APC.APCConfigManager.get_apc_config_base()\n",
    "\n",
    "config.num_epoch = 20\n",
    "config.spacy_model = \"de_core_news_sm\"\n",
    "config.model = APC.APCModelList.FAST_LSA_T_V2\n",
    "dataset = \"101.news_german_consolidated_with_commented\"\n",
    "checkpoint_path = \"../mv_checkpoints/\"\n",
    "\n",
    "MV = MetricVisualizer(name = \"plm_trial\")\n",
    "config.MV = MV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-03-23 11:18:00] (2.0.28) Set Model Device: cpu\n",
      "[2023-03-23 11:18:00] (2.0.28) Device Name: Unknown\n",
      "2023-03-23 11:18:01,335 INFO: PyABSA version: 2.0.28\n",
      "2023-03-23 11:18:01,337 INFO: Transformers version: 4.24.0\n",
      "2023-03-23 11:18:01,338 INFO: Torch version: 1.12.1+cudaNone\n",
      "2023-03-23 11:18:01,340 INFO: Device: Unknown\n",
      "2023-03-23 11:18:01,367 INFO: Searching dataset 101.news_german_consolidated_with_commented in local disk\n",
      "2023-03-23 11:18:01,406 INFO: You can set load_aug=True in a trainer to augment your dataset (English only yet) and improve performance.\n",
      "2023-03-23 11:18:01,407 INFO: Please use a new folder to perform new text augment if the former augment in datasets/apc_datasets/101.news_german_consolidated_with_commented errored unexpectedly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-german-dbmdz-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-23 11:18:07,609 INFO: Load dataset from datasets/apc_datasets/101.news_german_consolidated_with_commented/news_german.train.dat.apc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preparing dataloader:   0%|          | 0/172 [00:00<?, ?it/s]Using bos_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n",
      "preparing dataloader: 100%|██████████| 172/172 [00:00<00:00, 637.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-23 11:18:07,888 INFO: Dataset Label Details: {'neutral': 34, 'negative': 71, 'positive': 64, 'Sum': 169}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-23 11:18:08,065 INFO: train data examples:\n",
      " [{'ex_id': tensor(0), 'text_raw': 'Klimaschutz ist für Annalena Baerbock vor allem ein Kampf gegen die Autofahrer , behauptete Blume in der Augsburger Allgemeinen.', 'text_spc': '[CLS] Klimaschutz ist für Annalena Baerbock vor allem ein Kampf gegen die Autofahrer , behauptete Blume in der Augsburger Allgemeinen. [SEP] Annalena Baerbock [SEP]', 'aspect': 'Annalena Baerbock', 'aspect_position': tensor(0), 'lca_ids': tensor([0.9615, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9615, 0.9231, 0.8846, 0.8462, 0.8077,\n",
      "        0.7692, 0.7308, 0.6923, 0.6538, 0.6154, 0.5769, 0.5385, 0.5000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_vec': tensor(0), 'lcf_cdw_vec': tensor([0.9615, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9615, 0.9231, 0.8846, 0.8462, 0.8077,\n",
      "        0.7692, 0.7308, 0.6923, 0.6538, 0.6154, 0.5769, 0.5385, 0.5000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_cdm_vec': tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'lcfs_vec': tensor(0), 'lcfs_cdw_vec': tensor(0), 'lcfs_cdm_vec': tensor(0), 'dlcf_vec': tensor(0), 'dlcfs_vec': tensor(0), 'depend_vec': tensor(0), 'depended_vec': tensor(0), 'spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'text_indices': tensor([  102, 18548,   207,  9586,  6324,  3693, 30943,  1719, 18120,  1935,\n",
      "          249,  1384,   139,  3451,   466,   125, 10350,   806, 22941, 26577,\n",
      "          142,   127, 26952,  4288,   552,   103,  6324,  3693, 30943,  1719,\n",
      "        18120,  1935,   103,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'aspect_bert_indices': tensor(0), 'text_raw_bert_indices': tensor(0), 'polarity': tensor(0), 'cluster_ids': tensor([-100, -100, -100, -100,    0,    0,    0,    0,    0,    0, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100]), 'side_ex_ids': tensor(0), 'left_lcf_cdm_vec': tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'left_lcf_cdw_vec': tensor([0.9615, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9615, 0.9231, 0.8846, 0.8462, 0.8077,\n",
      "        0.7692, 0.7308, 0.6923, 0.6538, 0.6154, 0.5769, 0.5385, 0.5000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'left_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'left_text_indices': tensor([  102, 18548,   207,  9586,  6324,  3693, 30943,  1719, 18120,  1935,\n",
      "          249,  1384,   139,  3451,   466,   125, 10350,   806, 22941, 26577,\n",
      "          142,   127, 26952,  4288,   552,   103,  6324,  3693, 30943,  1719,\n",
      "        18120,  1935,   103,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'left_dist': tensor(0), 'right_lcf_cdm_vec': tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'right_lcf_cdw_vec': tensor([0.9615, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9615, 0.9231, 0.8846, 0.8462, 0.8077,\n",
      "        0.7692, 0.7308, 0.6923, 0.6538, 0.6154, 0.5769, 0.5385, 0.5000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'right_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'right_text_indices': tensor([  102, 18548,   207,  9586,  6324,  3693, 30943,  1719, 18120,  1935,\n",
      "          249,  1384,   139,  3451,   466,   125, 10350,   806, 22941, 26577,\n",
      "          142,   127, 26952,  4288,   552,   103,  6324,  3693, 30943,  1719,\n",
      "        18120,  1935,   103,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'right_dist': tensor(0)}, {'ex_id': tensor(1), 'text_raw': 'Nun habe Armin Laschet ein Problem, heißt es in einem Blogeintrag Webers von Montag.', 'text_spc': '[CLS] Nun habe Armin Laschet ein Problem, heißt es in einem Blogeintrag Webers von Montag. [SEP] Armin Laschet [SEP]', 'aspect': 'Armin Laschet', 'aspect_position': tensor(0), 'lca_ids': tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9565, 0.9130, 0.8696, 0.8261, 0.7826, 0.7391, 0.6957, 0.6522,\n",
      "        0.6087, 0.5652, 0.5217, 0.4783, 0.4348, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_vec': tensor(0), 'lcf_cdw_vec': tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9565, 0.9130, 0.8696, 0.8261, 0.7826, 0.7391, 0.6957, 0.6522,\n",
      "        0.6087, 0.5652, 0.5217, 0.4783, 0.4348, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_cdm_vec': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'lcfs_vec': tensor(0), 'lcfs_cdw_vec': tensor(0), 'lcfs_cdm_vec': tensor(0), 'dlcf_vec': tensor(0), 'dlcfs_vec': tensor(0), 'depend_vec': tensor(0), 'depended_vec': tensor(0), 'spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'text_indices': tensor([  102,  1000,   691, 15150,  5311,   383, 30942,   139,  1453,   806,\n",
      "         2560,   233,   142,   377, 11316,  2368,   578,  9911, 30941,   185,\n",
      "         3155,   552,   103, 15150,  5311,   383, 30942,   103,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'aspect_bert_indices': tensor(0), 'text_raw_bert_indices': tensor(0), 'polarity': tensor(0), 'cluster_ids': tensor([-100, -100, -100,    0,    0,    0,    0, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100]), 'side_ex_ids': tensor(0), 'left_lcf_cdm_vec': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'left_lcf_cdw_vec': tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9565, 0.9130, 0.8696, 0.8261, 0.7826, 0.7391, 0.6957, 0.6522,\n",
      "        0.6087, 0.5652, 0.5217, 0.4783, 0.4348, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'left_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'left_text_indices': tensor([  102,  1000,   691, 15150,  5311,   383, 30942,   139,  1453,   806,\n",
      "         2560,   233,   142,   377, 11316,  2368,   578,  9911, 30941,   185,\n",
      "         3155,   552,   103, 15150,  5311,   383, 30942,   103,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'left_dist': tensor(0), 'right_lcf_cdm_vec': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'right_lcf_cdw_vec': tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9565, 0.9130, 0.8696, 0.8261, 0.7826, 0.7391, 0.6957, 0.6522,\n",
      "        0.6087, 0.5652, 0.5217, 0.4783, 0.4348, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'right_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'right_text_indices': tensor([  102,  1000,   691, 15150,  5311,   383, 30942,   139,  1453,   806,\n",
      "         2560,   233,   142,   377, 11316,  2368,   578,  9911, 30941,   185,\n",
      "         3155,   552,   103, 15150,  5311,   383, 30942,   103,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'right_dist': tensor(0)}]\n",
      "2023-03-23 11:18:09,660 INFO: Load dataset from datasets/apc_datasets/101.news_german_consolidated_with_commented/news_german.test.dat.apc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preparing dataloader: 100%|██████████| 1367/1367 [00:02<00:00, 673.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-23 11:18:11,702 INFO: Dataset Label Details: {'neutral': 276, 'negative': 548, 'positive': 523, 'Sum': 1347}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-23 11:18:12,550 INFO: test data examples:\n",
      " [{'ex_id': tensor(0), 'text_raw': 'Noch vier Wochen bis zur Bundestagswahl: Umfragen sehen die SPD mit Kanzlerkandidat Olaf Scholz als stärkste Kraft - deutlich vor der Union.', 'text_spc': '[CLS] Noch vier Wochen bis zur Bundestagswahl: Umfragen sehen die SPD mit Kanzlerkandidat Olaf Scholz als stärkste Kraft - deutlich vor der Union. [SEP] Olaf Scholz [SEP]', 'aspect': 'Olaf Scholz', 'aspect_position': tensor(0), 'lca_ids': tensor([0.5714, 0.6071, 0.6429, 0.6786, 0.7143, 0.7500, 0.7857, 0.8214, 0.8571,\n",
      "        0.8929, 0.9286, 0.9643, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9643, 0.9286, 0.8929, 0.8571, 0.8214, 0.7857, 0.7500,\n",
      "        0.7143, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_vec': tensor(0), 'lcf_cdw_vec': tensor([0.5714, 0.6071, 0.6429, 0.6786, 0.7143, 0.7500, 0.7857, 0.8214, 0.8571,\n",
      "        0.8929, 0.9286, 0.9643, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9643, 0.9286, 0.8929, 0.8571, 0.8214, 0.7857, 0.7500,\n",
      "        0.7143, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'lcfs_vec': tensor(0), 'lcfs_cdw_vec': tensor(0), 'lcfs_cdm_vec': tensor(0), 'dlcf_vec': tensor(0), 'dlcfs_vec': tensor(0), 'depend_vec': tensor(0), 'depended_vec': tensor(0), 'spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'text_indices': tensor([  102,   414,   921,  2086,   336,   327, 20526,   847, 23249,  1374,\n",
      "          125,  3545,   183,  9179, 15442, 17616, 17945,   250,  2462,   227,\n",
      "         2588,   223,  2476,   249,   127,  2141,   552,   103, 17616, 17945,\n",
      "          103,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'aspect_bert_indices': tensor(0), 'text_raw_bert_indices': tensor(0), 'polarity': tensor(2), 'cluster_ids': tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100,    2,    2, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100]), 'side_ex_ids': tensor(0), 'left_lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'left_lcf_cdw_vec': tensor([0.5714, 0.6071, 0.6429, 0.6786, 0.7143, 0.7500, 0.7857, 0.8214, 0.8571,\n",
      "        0.8929, 0.9286, 0.9643, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9643, 0.9286, 0.8929, 0.8571, 0.8214, 0.7857, 0.7500,\n",
      "        0.7143, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'left_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'left_text_indices': tensor([  102,   414,   921,  2086,   336,   327, 20526,   847, 23249,  1374,\n",
      "          125,  3545,   183,  9179, 15442, 17616, 17945,   250,  2462,   227,\n",
      "         2588,   223,  2476,   249,   127,  2141,   552,   103, 17616, 17945,\n",
      "          103,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'left_dist': tensor(0), 'right_lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'right_lcf_cdw_vec': tensor([0.5714, 0.6071, 0.6429, 0.6786, 0.7143, 0.7500, 0.7857, 0.8214, 0.8571,\n",
      "        0.8929, 0.9286, 0.9643, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9643, 0.9286, 0.8929, 0.8571, 0.8214, 0.7857, 0.7500,\n",
      "        0.7143, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'right_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'right_text_indices': tensor([  102,   414,   921,  2086,   336,   327, 20526,   847, 23249,  1374,\n",
      "          125,  3545,   183,  9179, 15442, 17616, 17945,   250,  2462,   227,\n",
      "         2588,   223,  2476,   249,   127,  2141,   552,   103, 17616, 17945,\n",
      "          103,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'right_dist': tensor(0)}, {'ex_id': tensor(1), 'text_raw': 'Er kritisierte den Vorwurf der Grünen, dass es sich hier um eine Rufmordkampagne handle, weil Medien über die Plagiate berichten: \"Die Grünen sprechen von einer \\'Kampagne\\' gegen Annalena Baerbock .', 'text_spc': '[CLS] Er kritisierte den Vorwurf der Grünen, dass es sich hier um eine Rufmordkampagne handle, weil Medien über die Plagiate berichten: \"Die Grünen sprechen von einer \\'Kampagne\\' gegen Annalena Baerbock . [SEP] Annalena Baerbock [SEP]', 'aspect': 'Annalena Baerbock', 'aspect_position': tensor(0), 'lca_ids': tensor([0.2292, 0.2500, 0.2708, 0.2917, 0.3125, 0.3333, 0.3542, 0.3750, 0.3958,\n",
      "        0.4167, 0.4375, 0.4583, 0.4792, 0.5000, 0.5208, 0.5417, 0.5625, 0.5833,\n",
      "        0.6042, 0.6250, 0.6458, 0.6667, 0.6875, 0.7083, 0.7292, 0.7500, 0.7708,\n",
      "        0.7917, 0.8125, 0.8333, 0.8542, 0.8750, 0.8958, 0.9167, 0.9375, 0.9583,\n",
      "        0.9792, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_vec': tensor(0), 'lcf_cdw_vec': tensor([0.2292, 0.2500, 0.2708, 0.2917, 0.3125, 0.3333, 0.3542, 0.3750, 0.3958,\n",
      "        0.4167, 0.4375, 0.4583, 0.4792, 0.5000, 0.5208, 0.5417, 0.5625, 0.5833,\n",
      "        0.6042, 0.6250, 0.6458, 0.6667, 0.6875, 0.7083, 0.7292, 0.7500, 0.7708,\n",
      "        0.7917, 0.8125, 0.8333, 0.8542, 0.8750, 0.8958, 0.9167, 0.9375, 0.9583,\n",
      "        0.9792, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'lcfs_vec': tensor(0), 'lcfs_cdw_vec': tensor(0), 'lcfs_cdm_vec': tensor(0), 'dlcf_vec': tensor(0), 'dlcfs_vec': tensor(0), 'depend_vec': tensor(0), 'depended_vec': tensor(0), 'spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'text_indices': tensor([  102,   159, 13971,   179, 16008,   127, 29393,   106,   806,   347,\n",
      "          233,   235,   532,   271,   238,  6590,  8891, 21373, 28372,   806,\n",
      "         1196,  3324, 24026,   125,  2494, 21583,   124,  8448,   847,   215,\n",
      "          125, 29393,   106,  3902,   185,   343,  2075, 14435,  2075,   466,\n",
      "         6324,  3693, 30943,  1719, 18120,  1935,   552,   103,  6324,  3693,\n",
      "        30943,  1719, 18120,  1935,   103,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'aspect_bert_indices': tensor(0), 'text_raw_bert_indices': tensor(0), 'polarity': tensor(0), 'cluster_ids': tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100,    0,    0,    0,    0,    0,    0, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100]), 'side_ex_ids': tensor(0), 'left_lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'left_lcf_cdw_vec': tensor([0.2292, 0.2500, 0.2708, 0.2917, 0.3125, 0.3333, 0.3542, 0.3750, 0.3958,\n",
      "        0.4167, 0.4375, 0.4583, 0.4792, 0.5000, 0.5208, 0.5417, 0.5625, 0.5833,\n",
      "        0.6042, 0.6250, 0.6458, 0.6667, 0.6875, 0.7083, 0.7292, 0.7500, 0.7708,\n",
      "        0.7917, 0.8125, 0.8333, 0.8542, 0.8750, 0.8958, 0.9167, 0.9375, 0.9583,\n",
      "        0.9792, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'left_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'left_text_indices': tensor([  102,   159, 13971,   179, 16008,   127, 29393,   106,   806,   347,\n",
      "          233,   235,   532,   271,   238,  6590,  8891, 21373, 28372,   806,\n",
      "         1196,  3324, 24026,   125,  2494, 21583,   124,  8448,   847,   215,\n",
      "          125, 29393,   106,  3902,   185,   343,  2075, 14435,  2075,   466,\n",
      "         6324,  3693, 30943,  1719, 18120,  1935,   552,   103,  6324,  3693,\n",
      "        30943,  1719, 18120,  1935,   103,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'left_dist': tensor(0), 'right_lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'right_lcf_cdw_vec': tensor([0.2292, 0.2500, 0.2708, 0.2917, 0.3125, 0.3333, 0.3542, 0.3750, 0.3958,\n",
      "        0.4167, 0.4375, 0.4583, 0.4792, 0.5000, 0.5208, 0.5417, 0.5625, 0.5833,\n",
      "        0.6042, 0.6250, 0.6458, 0.6667, 0.6875, 0.7083, 0.7292, 0.7500, 0.7708,\n",
      "        0.7917, 0.8125, 0.8333, 0.8542, 0.8750, 0.8958, 0.9167, 0.9375, 0.9583,\n",
      "        0.9792, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'right_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'right_text_indices': tensor([  102,   159, 13971,   179, 16008,   127, 29393,   106,   806,   347,\n",
      "          233,   235,   532,   271,   238,  6590,  8891, 21373, 28372,   806,\n",
      "         1196,  3324, 24026,   125,  2494, 21583,   124,  8448,   847,   215,\n",
      "          125, 29393,   106,  3902,   185,   343,  2075, 14435,  2075,   466,\n",
      "         6324,  3693, 30943,  1719, 18120,  1935,   552,   103,  6324,  3693,\n",
      "        30943,  1719, 18120,  1935,   103,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'right_dist': tensor(0)}]\n",
      "2023-03-23 11:18:14,325 INFO: Load dataset from datasets/apc_datasets/101.news_german_consolidated_with_commented/news_german.valid.dat.apc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preparing dataloader: 100%|██████████| 172/172 [00:00<00:00, 488.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-23 11:18:14,683 INFO: Dataset Label Details: {'neutral': 41, 'negative': 67, 'positive': 61, 'Sum': 169}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-23 11:18:14,842 INFO: valid data examples:\n",
      " [{'ex_id': tensor(0), 'text_raw': 'Die Gruppe fordert ein öffentliches Gespräch mit den Kanzlerkandidat*innen Armin Laschet (CDU), Olaf Scholz (SPD) und Annalena Baerbock (Grüne) noch vor der Bundestagswahl.', 'text_spc': '[CLS] Die Gruppe fordert ein öffentliches Gespräch mit den Kanzlerkandidat*innen Armin Laschet (CDU), Olaf Scholz (SPD) und Annalena Baerbock (Grüne) noch vor der Bundestagswahl. [SEP] Olaf Scholz [SEP]', 'aspect': 'Olaf Scholz', 'aspect_position': tensor(0), 'lca_ids': tensor([0.5435, 0.5652, 0.5870, 0.6087, 0.6304, 0.6522, 0.6739, 0.6957, 0.7174,\n",
      "        0.7391, 0.7609, 0.7826, 0.8043, 0.8261, 0.8478, 0.8696, 0.8913, 0.9130,\n",
      "        0.9348, 0.9565, 0.9783, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9783, 0.9565, 0.9348, 0.9130, 0.8913, 0.8696, 0.8478,\n",
      "        0.8261, 0.8043, 0.7826, 0.7609, 0.7391, 0.7174, 0.6957, 0.6739, 0.6522,\n",
      "        0.6304, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_vec': tensor(0), 'lcf_cdw_vec': tensor([0.5435, 0.5652, 0.5870, 0.6087, 0.6304, 0.6522, 0.6739, 0.6957, 0.7174,\n",
      "        0.7391, 0.7609, 0.7826, 0.8043, 0.8261, 0.8478, 0.8696, 0.8913, 0.9130,\n",
      "        0.9348, 0.9565, 0.9783, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9783, 0.9565, 0.9348, 0.9130, 0.8913, 0.8696, 0.8478,\n",
      "        0.8261, 0.8043, 0.7826, 0.7609, 0.7391, 0.7174, 0.6957, 0.6739, 0.6522,\n",
      "        0.6304, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'lcfs_vec': tensor(0), 'lcfs_cdw_vec': tensor(0), 'lcfs_cdm_vec': tensor(0), 'dlcf_vec': tensor(0), 'dlcfs_vec': tensor(0), 'depend_vec': tensor(0), 'depended_vec': tensor(0), 'spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'text_indices': tensor([  102,   125,  2434,  6780,   139,  1517,  5551, 30941, 20998,   175,\n",
      "          183,   179,  9179, 15442,  1158,  2569, 15150,  5311,   383, 30942,\n",
      "          194,  4514,  2458,   806, 17616, 17945,   194,  3545,  2458,   143,\n",
      "         6324,  3693, 30943,  1719, 18120,  1935,   194, 29393, 30937,  2458,\n",
      "          414,   249,   127, 20526,   552,   103, 17616, 17945,   103,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'aspect_bert_indices': tensor(0), 'text_raw_bert_indices': tensor(0), 'polarity': tensor(1), 'cluster_ids': tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "           1,    1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100]), 'side_ex_ids': tensor(0), 'left_lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'left_lcf_cdw_vec': tensor([0.5435, 0.5652, 0.5870, 0.6087, 0.6304, 0.6522, 0.6739, 0.6957, 0.7174,\n",
      "        0.7391, 0.7609, 0.7826, 0.8043, 0.8261, 0.8478, 0.8696, 0.8913, 0.9130,\n",
      "        0.9348, 0.9565, 0.9783, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9783, 0.9565, 0.9348, 0.9130, 0.8913, 0.8696, 0.8478,\n",
      "        0.8261, 0.8043, 0.7826, 0.7609, 0.7391, 0.7174, 0.6957, 0.6739, 0.6522,\n",
      "        0.6304, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'left_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'left_text_indices': tensor([  102,   125,  2434,  6780,   139,  1517,  5551, 30941, 20998,   175,\n",
      "          183,   179,  9179, 15442,  1158,  2569, 15150,  5311,   383, 30942,\n",
      "          194,  4514,  2458,   806, 17616, 17945,   194,  3545,  2458,   143,\n",
      "         6324,  3693, 30943,  1719, 18120,  1935,   194, 29393, 30937,  2458,\n",
      "          414,   249,   127, 20526,   552,   103, 17616, 17945,   103,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'left_dist': tensor(0), 'right_lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'right_lcf_cdw_vec': tensor([0.5435, 0.5652, 0.5870, 0.6087, 0.6304, 0.6522, 0.6739, 0.6957, 0.7174,\n",
      "        0.7391, 0.7609, 0.7826, 0.8043, 0.8261, 0.8478, 0.8696, 0.8913, 0.9130,\n",
      "        0.9348, 0.9565, 0.9783, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9783, 0.9565, 0.9348, 0.9130, 0.8913, 0.8696, 0.8478,\n",
      "        0.8261, 0.8043, 0.7826, 0.7609, 0.7391, 0.7174, 0.6957, 0.6739, 0.6522,\n",
      "        0.6304, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'right_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'right_text_indices': tensor([  102,   125,  2434,  6780,   139,  1517,  5551, 30941, 20998,   175,\n",
      "          183,   179,  9179, 15442,  1158,  2569, 15150,  5311,   383, 30942,\n",
      "          194,  4514,  2458,   806, 17616, 17945,   194,  3545,  2458,   143,\n",
      "         6324,  3693, 30943,  1719, 18120,  1935,   194, 29393, 30937,  2458,\n",
      "          414,   249,   127, 20526,   552,   103, 17616, 17945,   103,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'right_dist': tensor(0)}, {'ex_id': tensor(1), 'text_raw': 'Der begann am Freitagabend, als Armin Laschet sich zuschalten ließ in eine Programmkonferenz der CSU.', 'text_spc': '[CLS] Der begann am Freitagabend, als Armin Laschet sich zuschalten ließ in eine Programmkonferenz der CSU. [SEP] Armin Laschet [SEP]', 'aspect': 'Armin Laschet', 'aspect_position': tensor(0), 'lca_ids': tensor([0.8261, 0.8696, 0.9130, 0.9565, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9565, 0.9130, 0.8696, 0.8261,\n",
      "        0.7826, 0.7391, 0.6957, 0.6522, 0.6087, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_vec': tensor(0), 'lcf_cdw_vec': tensor([0.8261, 0.8696, 0.9130, 0.9565, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9565, 0.9130, 0.8696, 0.8261,\n",
      "        0.7826, 0.7391, 0.6957, 0.6522, 0.6087, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_cdm_vec': tensor([0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'lcfs_vec': tensor(0), 'lcfs_cdw_vec': tensor(0), 'lcfs_cdm_vec': tensor(0), 'dlcf_vec': tensor(0), 'dlcfs_vec': tensor(0), 'depend_vec': tensor(0), 'depended_vec': tensor(0), 'spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'text_indices': tensor([  102,   127,  2332,   266, 17337,   806,   250, 15150,  5311,   383,\n",
      "        30942,   235,  4670,  2604,  3232,   142,   238,  2088,  7117,   127,\n",
      "         6825,   552,   103, 15150,  5311,   383, 30942,   103,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'aspect_bert_indices': tensor(0), 'text_raw_bert_indices': tensor(0), 'polarity': tensor(1), 'cluster_ids': tensor([-100, -100, -100, -100, -100, -100, -100,    1,    1,    1,    1, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100]), 'side_ex_ids': tensor(0), 'left_lcf_cdm_vec': tensor([0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'left_lcf_cdw_vec': tensor([0.8261, 0.8696, 0.9130, 0.9565, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9565, 0.9130, 0.8696, 0.8261,\n",
      "        0.7826, 0.7391, 0.6957, 0.6522, 0.6087, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'left_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'left_text_indices': tensor([  102,   127,  2332,   266, 17337,   806,   250, 15150,  5311,   383,\n",
      "        30942,   235,  4670,  2604,  3232,   142,   238,  2088,  7117,   127,\n",
      "         6825,   552,   103, 15150,  5311,   383, 30942,   103,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'left_dist': tensor(0), 'right_lcf_cdm_vec': tensor([0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'right_lcf_cdw_vec': tensor([0.8261, 0.8696, 0.9130, 0.9565, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9565, 0.9130, 0.8696, 0.8261,\n",
      "        0.7826, 0.7391, 0.6957, 0.6522, 0.6087, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'right_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'right_text_indices': tensor([  102,   127,  2332,   266, 17337,   806,   250, 15150,  5311,   383,\n",
      "        30942,   235,  4670,  2604,  3232,   142,   238,  2088,  7117,   127,\n",
      "         6825,   552,   103, 15150,  5311,   383, 30942,   103,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'right_dist': tensor(0)}]\n",
      "[2023-03-23 11:18:14] (2.0.28) \u001b[31mCaching dataset... please remove cached dataset if any problem happens.\u001b[0m\n",
      "2023-03-23 11:18:19,997 INFO: Model Architecture:\n",
      " APCEnsembler(\n",
      "  (models): ModuleList(\n",
      "    (0): FAST_LSA_T_V2(\n",
      "      (bert4global): BertModel(\n",
      "        (embeddings): BertEmbeddings(\n",
      "          (word_embeddings): Embedding(31102, 768, padding_idx=0)\n",
      "          (position_embeddings): Embedding(512, 768)\n",
      "          (token_type_embeddings): Embedding(2, 768)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (encoder): BertEncoder(\n",
      "          (layer): ModuleList(\n",
      "            (0): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (1): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (2): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (3): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (4): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (5): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (6): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (7): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (8): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (9): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (10): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (11): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (pooler): BertPooler(\n",
      "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (activation): Tanh()\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0, inplace=False)\n",
      "      (post_encoder): Encoder(\n",
      "        (encoder): ModuleList(\n",
      "          (0): SelfAttention(\n",
      "            (SA): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (tanh): Tanh()\n",
      "      )\n",
      "      (post_encoder_): Encoder(\n",
      "        (encoder): ModuleList(\n",
      "          (0): SelfAttention(\n",
      "            (SA): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (tanh): Tanh()\n",
      "      )\n",
      "      (bert_pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "      (CDW_LSA): LSA(\n",
      "        (encoder): Encoder(\n",
      "          (encoder): ModuleList(\n",
      "            (0): SelfAttention(\n",
      "              (SA): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (tanh): Tanh()\n",
      "        )\n",
      "        (encoder_left): Encoder(\n",
      "          (encoder): ModuleList(\n",
      "            (0): SelfAttention(\n",
      "              (SA): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (tanh): Tanh()\n",
      "        )\n",
      "        (encoder_right): Encoder(\n",
      "          (encoder): ModuleList(\n",
      "            (0): SelfAttention(\n",
      "              (SA): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (tanh): Tanh()\n",
      "        )\n",
      "        (linear_window_3h): Linear(in_features=2304, out_features=768, bias=True)\n",
      "        (linear_window_2h): Linear(in_features=1536, out_features=768, bias=True)\n",
      "      )\n",
      "      (post_linear): Linear(in_features=1536, out_features=768, bias=True)\n",
      "      (dense): Linear(in_features=768, out_features=3, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(31102, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dense): Linear(in_features=3, out_features=3, bias=True)\n",
      ")\n",
      "2023-03-23 11:18:20,000 INFO: ABSADatasetsVersion:None\t-->\tCalling Count:0\n",
      "2023-03-23 11:18:20,002 INFO: MV:<metric_visualizer.metric_visualizer.MetricVisualizer object at 0x7f6c510ef7f0>\t-->\tCalling Count:0\n",
      "2023-03-23 11:18:20,003 INFO: PyABSAVersion:2.0.28\t-->\tCalling Count:1\n",
      "2023-03-23 11:18:20,005 INFO: SRD:3\t-->\tCalling Count:3370\n",
      "2023-03-23 11:18:20,007 INFO: TorchVersion:1.12.1+cudaNone\t-->\tCalling Count:1\n",
      "2023-03-23 11:18:20,008 INFO: TransformersVersion:4.24.0\t-->\tCalling Count:1\n",
      "2023-03-23 11:18:20,011 INFO: auto_device:True\t-->\tCalling Count:3\n",
      "2023-03-23 11:18:20,014 INFO: batch_size:16\t-->\tCalling Count:3\n",
      "2023-03-23 11:18:20,015 INFO: cache_dataset:True\t-->\tCalling Count:1\n",
      "2023-03-23 11:18:20,016 INFO: checkpoint_save_mode:1\t-->\tCalling Count:3\n",
      "2023-03-23 11:18:20,017 INFO: cross_validate_fold:-1\t-->\tCalling Count:1\n",
      "2023-03-23 11:18:20,018 INFO: dataset_file:{'train': ['datasets/apc_datasets/101.news_german_consolidated_with_commented/news_german.train.dat.apc'], 'test': ['datasets/apc_datasets/101.news_german_consolidated_with_commented/news_german.test.dat.apc'], 'valid': ['datasets/apc_datasets/101.news_german_consolidated_with_commented/news_german.valid.dat.apc']}\t-->\tCalling Count:15\n",
      "2023-03-23 11:18:20,019 INFO: dataset_name:custom_dataset\t-->\tCalling Count:1\n",
      "2023-03-23 11:18:20,020 INFO: dca_layer:3\t-->\tCalling Count:0\n",
      "2023-03-23 11:18:20,021 INFO: dca_p:1\t-->\tCalling Count:0\n",
      "2023-03-23 11:18:20,022 INFO: deep_ensemble:False\t-->\tCalling Count:0\n",
      "2023-03-23 11:18:20,024 INFO: device:cpu\t-->\tCalling Count:3\n",
      "2023-03-23 11:18:20,025 INFO: device_name:Unknown\t-->\tCalling Count:1\n",
      "2023-03-23 11:18:20,027 INFO: dlcf_a:2\t-->\tCalling Count:0\n",
      "2023-03-23 11:18:20,029 INFO: dropout:0\t-->\tCalling Count:1\n",
      "2023-03-23 11:18:20,032 INFO: dynamic_truncate:True\t-->\tCalling Count:3370\n",
      "2023-03-23 11:18:20,034 INFO: embed_dim:768\t-->\tCalling Count:7\n",
      "2023-03-23 11:18:20,035 INFO: eta:1\t-->\tCalling Count:2\n",
      "2023-03-23 11:18:20,037 INFO: eta_lr:0.1\t-->\tCalling Count:1\n",
      "2023-03-23 11:18:20,039 INFO: evaluate_begin:0\t-->\tCalling Count:0\n",
      "2023-03-23 11:18:20,040 INFO: from_checkpoint:None\t-->\tCalling Count:0\n",
      "2023-03-23 11:18:20,040 INFO: hidden_dim:768\t-->\tCalling Count:0\n",
      "2023-03-23 11:18:20,041 INFO: index_to_label:{0: 'negative', 1: 'neutral', 2: 'positive'}\t-->\tCalling Count:3\n",
      "2023-03-23 11:18:20,043 INFO: inference_model:None\t-->\tCalling Count:0\n",
      "2023-03-23 11:18:20,048 INFO: initializer:xavier_uniform_\t-->\tCalling Count:0\n",
      "2023-03-23 11:18:20,050 INFO: inputs_cols:['lcf_cdm_vec', 'lcf_cdw_vec', 'left_lcf_cdm_vec', 'left_lcf_cdw_vec', 'right_lcf_cdm_vec', 'right_lcf_cdw_vec', 'spc_mask_vec', 'text_indices']\t-->\tCalling Count:25281\n",
      "2023-03-23 11:18:20,051 INFO: l2reg:1e-06\t-->\tCalling Count:2\n",
      "2023-03-23 11:18:20,052 INFO: label_to_index:{'negative': 0, 'neutral': 1, 'positive': 2}\t-->\tCalling Count:0\n",
      "2023-03-23 11:18:20,053 INFO: lcf:cdw\t-->\tCalling Count:3\n",
      "2023-03-23 11:18:20,055 INFO: learning_rate:2e-05\t-->\tCalling Count:1\n",
      "2023-03-23 11:18:20,056 INFO: load_aug:False\t-->\tCalling Count:1\n",
      "2023-03-23 11:18:20,057 INFO: log_step:10\t-->\tCalling Count:0\n",
      "2023-03-23 11:18:20,058 INFO: logger:<Logger fast_lsa_t_v2 (INFO)>\t-->\tCalling Count:16\n",
      "2023-03-23 11:18:20,059 INFO: lsa:False\t-->\tCalling Count:0\n",
      "2023-03-23 11:18:20,061 INFO: max_seq_len:80\t-->\tCalling Count:20220\n",
      "2023-03-23 11:18:20,066 INFO: model:<class 'pyabsa.tasks.AspectPolarityClassification.models.__lcf__.fast_lsa_t_v2.FAST_LSA_T_V2'>\t-->\tCalling Count:4\n",
      "2023-03-23 11:18:20,068 INFO: model_name:fast_lsa_t_v2\t-->\tCalling Count:3372\n",
      "2023-03-23 11:18:20,068 INFO: model_path_to_save:/home/steffen/thesis/mv_heckpoints/\t-->\tCalling Count:0\n",
      "2023-03-23 11:18:20,069 INFO: num_epoch:20\t-->\tCalling Count:0\n",
      "2023-03-23 11:18:20,070 INFO: optimizer:adamw\t-->\tCalling Count:1\n",
      "2023-03-23 11:18:20,071 INFO: output_dim:3\t-->\tCalling Count:3\n",
      "2023-03-23 11:18:20,072 INFO: overwrite_cache:False\t-->\tCalling Count:1\n",
      "2023-03-23 11:18:20,072 INFO: path_to_save:/home/steffen/thesis/mv_heckpoints/\t-->\tCalling Count:2\n",
      "2023-03-23 11:18:20,073 INFO: patience:5\t-->\tCalling Count:0\n",
      "2023-03-23 11:18:20,074 INFO: pretrained_bert:bert-base-german-dbmdz-uncased\t-->\tCalling Count:5\n",
      "2023-03-23 11:18:20,074 INFO: save_mode:1\t-->\tCalling Count:0\n",
      "2023-03-23 11:18:20,075 INFO: seed:52\t-->\tCalling Count:7\n",
      "2023-03-23 11:18:20,076 INFO: sigma:0.3\t-->\tCalling Count:0\n",
      "2023-03-23 11:18:20,081 INFO: similarity_threshold:1\t-->\tCalling Count:3\n",
      "2023-03-23 11:18:20,083 INFO: spacy_model:de_core_news_sm\t-->\tCalling Count:6\n",
      "2023-03-23 11:18:20,084 INFO: srd_alignment:True\t-->\tCalling Count:0\n",
      "2023-03-23 11:18:20,085 INFO: task_code:APC\t-->\tCalling Count:1\n",
      "2023-03-23 11:18:20,086 INFO: task_name:Aspect-based Sentiment Classification\t-->\tCalling Count:0\n",
      "2023-03-23 11:18:20,087 INFO: tokenizer:PreTrainedTokenizerFast(name_or_path='bert-base-german-dbmdz-uncased', vocab_size=31102, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\t-->\tCalling Count:0\n",
      "2023-03-23 11:18:20,088 INFO: use_amp:False\t-->\tCalling Count:1\n",
      "2023-03-23 11:18:20,089 INFO: use_bert_spc:True\t-->\tCalling Count:0\n",
      "2023-03-23 11:18:20,090 INFO: use_syntax_based_SRD:False\t-->\tCalling Count:0\n",
      "2023-03-23 11:18:20,091 INFO: warmup_step:-1\t-->\tCalling Count:0\n",
      "2023-03-23 11:18:20,092 INFO: window:lr\t-->\tCalling Count:0\n",
      "2023-03-23 11:18:20,103 INFO: ***** Running training for Aspect-based Sentiment Classification *****\n",
      "2023-03-23 11:18:20,105 INFO: Training set examples = 169\n",
      "2023-03-23 11:18:20,106 INFO: Test set examples = 1347\n",
      "2023-03-23 11:18:20,107 INFO: Total params = 123510545, Trainable params = 123510545, Non-trainable params = 0\n",
      "2023-03-23 11:18:20,108 INFO: Batch size = 16\n",
      "2023-03-23 11:18:20,108 INFO: Num steps = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Smooth Loss: 1.0790: 100%|██████████| 11/11 [02:36<00:00, 14.23s/it, Dev Acc:39.64(max:39.64) Dev F1:18.93(max:18.93)]\n",
      "Epoch:  1 | Smooth Loss: 1.0615: 100%|██████████| 11/11 [02:15<00:00, 12.32s/it, Dev Acc:39.05(max:39.64) Dev F1:18.72(max:18.93)]\n",
      "Epoch:  2 | Smooth Loss: 1.0494: 100%|██████████| 11/11 [02:09<00:00, 11.75s/it, Dev Acc:35.50(max:39.64) Dev F1:25.46(max:25.46)]\n",
      "Epoch:  3 | Smooth Loss: 1.0309: 100%|██████████| 11/11 [01:33<00:00,  8.49s/it, Dev Acc:39.64(max:39.64) Dev F1:28.81(max:28.81)]\n",
      "Epoch:  4 | Smooth Loss: 0.9984: 100%|██████████| 11/11 [01:20<00:00,  7.28s/it, Dev Acc:44.97(max:44.97) Dev F1:41.88(max:41.88)]\n",
      "Epoch:  5 | Smooth Loss: 0.9393: 100%|██████████| 11/11 [01:35<00:00,  8.69s/it, Dev Acc:52.66(max:52.66) Dev F1:51.52(max:51.52)]\n",
      "Epoch:  6 | Smooth Loss: 0.8472: 100%|██████████| 11/11 [01:34<00:00,  8.61s/it, Dev Acc:57.40(max:57.40) Dev F1:55.52(max:55.52)]\n",
      "Epoch:  7 | Smooth Loss: 0.7549: 100%|██████████| 11/11 [01:33<00:00,  8.46s/it, Dev Acc:55.03(max:57.40) Dev F1:53.01(max:55.52)]\n",
      "Epoch:  8 | Smooth Loss: 0.6761: 100%|██████████| 11/11 [01:46<00:00,  9.68s/it, Dev Acc:53.25(max:57.40) Dev F1:51.64(max:55.52)]\n",
      "Epoch:  9 | Smooth Loss: 0.6171: 100%|██████████| 11/11 [02:08<00:00, 11.68s/it, Dev Acc:55.62(max:57.40) Dev F1:54.29(max:55.83)]\n",
      "Epoch: 10 | Smooth Loss: 0.5604: 100%|██████████| 11/11 [01:31<00:00,  8.33s/it, Dev Acc:55.03(max:57.40) Dev F1:55.36(max:55.83)]\n",
      "Epoch: 11 | Smooth Loss: 0.5172: 100%|██████████| 11/11 [01:32<00:00,  8.38s/it, Dev Acc:57.40(max:57.40) Dev F1:57.81(max:57.81)]\n",
      "Epoch: 12 | Smooth Loss: 0.4786: 100%|██████████| 11/11 [01:32<00:00,  8.39s/it, Dev Acc:53.25(max:57.40) Dev F1:53.41(max:57.81)]\n",
      "Epoch: 13 | Smooth Loss: 0.4449: 100%|██████████| 11/11 [01:36<00:00,  8.78s/it, Dev Acc:51.48(max:57.40) Dev F1:51.78(max:57.81)]\n",
      "Epoch: 14 | Smooth Loss: 0.4156: 100%|██████████| 11/11 [02:01<00:00, 11.07s/it, Dev Acc:50.89(max:57.40) Dev F1:51.22(max:57.81)]\n",
      "Epoch: 15 | Smooth Loss: 0.3898: 100%|██████████| 11/11 [01:49<00:00,  9.95s/it, Dev Acc:52.07(max:57.40) Dev F1:52.46(max:57.81)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-03-23 11:46:57] (2.0.28) Loading best model: /home/steffen/thesis/mv_heckpoints//fast_lsa_t_v2_custom_dataset_acc_57.4_f1_57.81/ and evaluating on test set \n",
      "2023-03-23 11:49:48,844 INFO: \n",
      "------------------------------------------------------ Metrics Table ------------------------------------------------------\n",
      "╒═════════════════════════════════════════════════════════════╤══════════════════════════════╤═════════════════════════════╕\n",
      "│ Trial                                                       │ average-Max-Test-Acc (std)   │ average-Max-Test-F1 (std)   │\n",
      "╞═════════════════════════════════════════════════════════════╪══════════════════════════════╪═════════════════════════════╡\n",
      "│ fast_lsa_t_v2-custom_dataset-bert-base-german-dbmdz-uncased │ 61.32 (0.0)                  │ 57.99 (0.0)                 │\n",
      "╘═════════════════════════════════════════════════════════════╧══════════════════════════════╧═════════════════════════════╛\n",
      "------------------------------------- https://github.com/yangheng95/metric_visualizer -------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steffen/.conda/envs/thesis/lib/python3.10/site-packages/metric_visualizer/utils.py:25: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  self.skewness = stats.skew(self.data, keepdims=True)\n",
      "/home/steffen/.conda/envs/thesis/lib/python3.10/site-packages/pyabsa/framework/trainer_class/trainer_template.py:228: ResourceWarning: unclosed file <_io.TextIOWrapper name='/home/steffen/Nextcloud/uni/22-ws/thesis-personalities/code/logs/fast_lsa_t_v2_20230323 111747/trainer.log' mode='a' encoding='utf8'>\n",
      "  self.config.logger.removeHandler(self.config.logger.handlers[0])\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-03-23 11:49:51] (2.0.28) Set Model Device: cpu\n",
      "[2023-03-23 11:49:51] (2.0.28) Device Name: Unknown\n",
      "2023-03-23 11:49:52,571 INFO: PyABSA version: 2.0.28\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2023-03-23 11:49:52,579 INFO: Transformers version: 4.24.0\n",
      "2023-03-23 11:49:52,580 INFO: Torch version: 1.12.1+cudaNone\n",
      "2023-03-23 11:49:52,582 INFO: Device: Unknown\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2023-03-23 11:49:52,662 INFO: Searching dataset 101.news_german_consolidated_with_commented in local disk\n",
      "2023-03-23 11:49:52,724 INFO: You can set load_aug=True in a trainer to augment your dataset (English only yet) and improve performance.\n",
      "2023-03-23 11:49:52,725 INFO: Please use a new folder to perform new text augment if the former augment in datasets/apc_datasets/101.news_german_consolidated_with_commented errored unexpectedly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steffen/.conda/envs/thesis/lib/python3.10/multiprocessing/pool.py:268: ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.Pool state=RUN pool_size=1>\n",
      "  _warn(f\"unclosed running multiprocessing pool {self!r}\",\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "Some weights of the model checkpoint at bert-base-german-dbmdz-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-23 11:49:57,461 INFO: Load dataset from datasets/apc_datasets/101.news_german_consolidated_with_commented/news_german.train.dat.apc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preparing dataloader:   0%|          | 0/172 [00:00<?, ?it/s]Using bos_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n",
      "preparing dataloader: 100%|██████████| 172/172 [00:00<00:00, 868.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-23 11:49:57,664 INFO: Dataset Label Details: {'neutral': 34, 'negative': 71, 'positive': 64, 'Sum': 169}\n",
      "2023-03-23 11:49:57,802 INFO: train data examples:\n",
      " [{'ex_id': tensor(0), 'text_raw': 'Klimaschutz ist für Annalena Baerbock vor allem ein Kampf gegen die Autofahrer , behauptete Blume in der Augsburger Allgemeinen.', 'text_spc': '[CLS] Klimaschutz ist für Annalena Baerbock vor allem ein Kampf gegen die Autofahrer , behauptete Blume in der Augsburger Allgemeinen. [SEP] Annalena Baerbock [SEP]', 'aspect': 'Annalena Baerbock', 'aspect_position': tensor(0), 'lca_ids': tensor([0.9615, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9615, 0.9231, 0.8846, 0.8462, 0.8077,\n",
      "        0.7692, 0.7308, 0.6923, 0.6538, 0.6154, 0.5769, 0.5385, 0.5000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_vec': tensor(0), 'lcf_cdw_vec': tensor([0.9615, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9615, 0.9231, 0.8846, 0.8462, 0.8077,\n",
      "        0.7692, 0.7308, 0.6923, 0.6538, 0.6154, 0.5769, 0.5385, 0.5000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_cdm_vec': tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'lcfs_vec': tensor(0), 'lcfs_cdw_vec': tensor(0), 'lcfs_cdm_vec': tensor(0), 'dlcf_vec': tensor(0), 'dlcfs_vec': tensor(0), 'depend_vec': tensor(0), 'depended_vec': tensor(0), 'spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'text_indices': tensor([  102, 20206,   215,   231,  6886,  2829, 30887,  6158, 15105,  1597,\n",
      "          334,  1416,   143,  3639,   574,   128, 12334,   818, 25285, 29605,\n",
      "          153,   125, 29429, 10799,   566,   103,  6886,  2829, 30887,  6158,\n",
      "        15105,  1597,   103,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'aspect_bert_indices': tensor(0), 'text_raw_bert_indices': tensor(0), 'polarity': tensor(0), 'cluster_ids': tensor([-100, -100, -100, -100,    0,    0,    0,    0,    0,    0, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100]), 'side_ex_ids': tensor(0), 'left_lcf_cdm_vec': tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'left_lcf_cdw_vec': tensor([0.9615, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9615, 0.9231, 0.8846, 0.8462, 0.8077,\n",
      "        0.7692, 0.7308, 0.6923, 0.6538, 0.6154, 0.5769, 0.5385, 0.5000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'left_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'left_text_indices': tensor([  102, 20206,   215,   231,  6886,  2829, 30887,  6158, 15105,  1597,\n",
      "          334,  1416,   143,  3639,   574,   128, 12334,   818, 25285, 29605,\n",
      "          153,   125, 29429, 10799,   566,   103,  6886,  2829, 30887,  6158,\n",
      "        15105,  1597,   103,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'left_dist': tensor(0), 'right_lcf_cdm_vec': tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'right_lcf_cdw_vec': tensor([0.9615, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9615, 0.9231, 0.8846, 0.8462, 0.8077,\n",
      "        0.7692, 0.7308, 0.6923, 0.6538, 0.6154, 0.5769, 0.5385, 0.5000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'right_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'right_text_indices': tensor([  102, 20206,   215,   231,  6886,  2829, 30887,  6158, 15105,  1597,\n",
      "          334,  1416,   143,  3639,   574,   128, 12334,   818, 25285, 29605,\n",
      "          153,   125, 29429, 10799,   566,   103,  6886,  2829, 30887,  6158,\n",
      "        15105,  1597,   103,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'right_dist': tensor(0)}, {'ex_id': tensor(1), 'text_raw': 'Nun habe Armin Laschet ein Problem, heißt es in einem Blogeintrag Webers von Montag.', 'text_spc': '[CLS] Nun habe Armin Laschet ein Problem, heißt es in einem Blogeintrag Webers von Montag. [SEP] Armin Laschet [SEP]', 'aspect': 'Armin Laschet', 'aspect_position': tensor(0), 'lca_ids': tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9565, 0.9130, 0.8696, 0.8261, 0.7826, 0.7391, 0.6957, 0.6522,\n",
      "        0.6087, 0.5652, 0.5217, 0.4783, 0.4348, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_vec': tensor(0), 'lcf_cdw_vec': tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9565, 0.9130, 0.8696, 0.8261, 0.7826, 0.7391, 0.6957, 0.6522,\n",
      "        0.6087, 0.5652, 0.5217, 0.4783, 0.4348, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_cdm_vec': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'lcfs_vec': tensor(0), 'lcfs_cdw_vec': tensor(0), 'lcfs_cdm_vec': tensor(0), 'dlcf_vec': tensor(0), 'dlcfs_vec': tensor(0), 'depend_vec': tensor(0), 'depended_vec': tensor(0), 'spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'text_indices': tensor([  102,  3171,   704, 16322, 11893,   441, 30885,   143,  1550,   818,\n",
      "         2701,   288,   153,   403, 13177,  2256,  1372, 11075, 30886,   195,\n",
      "         3393,   566,   103, 16322, 11893,   441, 30885,   103,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'aspect_bert_indices': tensor(0), 'text_raw_bert_indices': tensor(0), 'polarity': tensor(0), 'cluster_ids': tensor([-100, -100, -100,    0,    0,    0,    0, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100]), 'side_ex_ids': tensor(0), 'left_lcf_cdm_vec': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'left_lcf_cdw_vec': tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9565, 0.9130, 0.8696, 0.8261, 0.7826, 0.7391, 0.6957, 0.6522,\n",
      "        0.6087, 0.5652, 0.5217, 0.4783, 0.4348, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'left_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'left_text_indices': tensor([  102,  3171,   704, 16322, 11893,   441, 30885,   143,  1550,   818,\n",
      "         2701,   288,   153,   403, 13177,  2256,  1372, 11075, 30886,   195,\n",
      "         3393,   566,   103, 16322, 11893,   441, 30885,   103,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'left_dist': tensor(0), 'right_lcf_cdm_vec': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'right_lcf_cdw_vec': tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9565, 0.9130, 0.8696, 0.8261, 0.7826, 0.7391, 0.6957, 0.6522,\n",
      "        0.6087, 0.5652, 0.5217, 0.4783, 0.4348, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'right_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'right_text_indices': tensor([  102,  3171,   704, 16322, 11893,   441, 30885,   143,  1550,   818,\n",
      "         2701,   288,   153,   403, 13177,  2256,  1372, 11075, 30886,   195,\n",
      "         3393,   566,   103, 16322, 11893,   441, 30885,   103,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'right_dist': tensor(0)}]\n",
      "2023-03-23 11:49:58,899 INFO: Load dataset from datasets/apc_datasets/101.news_german_consolidated_with_commented/news_german.test.dat.apc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preparing dataloader: 100%|██████████| 1367/1367 [00:01<00:00, 982.85it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-23 11:50:00,304 INFO: Dataset Label Details: {'neutral': 276, 'negative': 548, 'positive': 523, 'Sum': 1347}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-23 11:50:00,952 INFO: test data examples:\n",
      " [{'ex_id': tensor(0), 'text_raw': 'Noch vier Wochen bis zur Bundestagswahl: Umfragen sehen die SPD mit Kanzlerkandidat Olaf Scholz als stärkste Kraft - deutlich vor der Union.', 'text_spc': '[CLS] Noch vier Wochen bis zur Bundestagswahl: Umfragen sehen die SPD mit Kanzlerkandidat Olaf Scholz als stärkste Kraft - deutlich vor der Union. [SEP] Olaf Scholz [SEP]', 'aspect': 'Olaf Scholz', 'aspect_position': tensor(0), 'lca_ids': tensor([0.5556, 0.5926, 0.6296, 0.6667, 0.7037, 0.7407, 0.7778, 0.8148, 0.8519,\n",
      "        0.8889, 0.9259, 0.9630, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9630, 0.9259, 0.8889, 0.8519, 0.8148, 0.7778, 0.7407,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_vec': tensor(0), 'lcf_cdw_vec': tensor([0.5556, 0.5926, 0.6296, 0.6667, 0.7037, 0.7407, 0.7778, 0.8148, 0.8519,\n",
      "        0.8889, 0.9259, 0.9630, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9630, 0.9259, 0.8889, 0.8519, 0.8148, 0.7778, 0.7407,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'lcfs_vec': tensor(0), 'lcfs_cdw_vec': tensor(0), 'lcfs_cdm_vec': tensor(0), 'dlcf_vec': tensor(0), 'dlcfs_vec': tensor(0), 'depend_vec': tensor(0), 'depended_vec': tensor(0), 'spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'text_indices': tensor([  102,  4314,  1285,  2168,   378,   356, 22417,   853, 25263,  1542,\n",
      "          128,  3752,   212,  9848, 21579, 21042, 19432,   276, 26066,  2832,\n",
      "          232,  2623,   334,   125,  2223,   566,   103, 21042, 19432,   103,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'aspect_bert_indices': tensor(0), 'text_raw_bert_indices': tensor(0), 'polarity': tensor(2), 'cluster_ids': tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100,    2,    2, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100]), 'side_ex_ids': tensor(0), 'left_lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'left_lcf_cdw_vec': tensor([0.5556, 0.5926, 0.6296, 0.6667, 0.7037, 0.7407, 0.7778, 0.8148, 0.8519,\n",
      "        0.8889, 0.9259, 0.9630, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9630, 0.9259, 0.8889, 0.8519, 0.8148, 0.7778, 0.7407,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'left_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'left_text_indices': tensor([  102,  4314,  1285,  2168,   378,   356, 22417,   853, 25263,  1542,\n",
      "          128,  3752,   212,  9848, 21579, 21042, 19432,   276, 26066,  2832,\n",
      "          232,  2623,   334,   125,  2223,   566,   103, 21042, 19432,   103,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'left_dist': tensor(0), 'right_lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'right_lcf_cdw_vec': tensor([0.5556, 0.5926, 0.6296, 0.6667, 0.7037, 0.7407, 0.7778, 0.8148, 0.8519,\n",
      "        0.8889, 0.9259, 0.9630, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9630, 0.9259, 0.8889, 0.8519, 0.8148, 0.7778, 0.7407,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'right_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'right_text_indices': tensor([  102,  4314,  1285,  2168,   378,   356, 22417,   853, 25263,  1542,\n",
      "          128,  3752,   212,  9848, 21579, 21042, 19432,   276, 26066,  2832,\n",
      "          232,  2623,   334,   125,  2223,   566,   103, 21042, 19432,   103,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'right_dist': tensor(0)}, {'ex_id': tensor(1), 'text_raw': 'Er kritisierte den Vorwurf der Grünen, dass es sich hier um eine Rufmordkampagne handle, weil Medien über die Plagiate berichten: \"Die Grünen sprechen von einer \\'Kampagne\\' gegen Annalena Baerbock .', 'text_spc': '[CLS] Er kritisierte den Vorwurf der Grünen, dass es sich hier um eine Rufmordkampagne handle, weil Medien über die Plagiate berichten: \"Die Grünen sprechen von einer \\'Kampagne\\' gegen Annalena Baerbock . [SEP] Annalena Baerbock [SEP]', 'aspect': 'Annalena Baerbock', 'aspect_position': tensor(0), 'lca_ids': tensor([0.2292, 0.2500, 0.2708, 0.2917, 0.3125, 0.3333, 0.3542, 0.3750, 0.3958,\n",
      "        0.4167, 0.4375, 0.4583, 0.4792, 0.5000, 0.5208, 0.5417, 0.5625, 0.5833,\n",
      "        0.6042, 0.6250, 0.6458, 0.6667, 0.6875, 0.7083, 0.7292, 0.7500, 0.7708,\n",
      "        0.7917, 0.8125, 0.8333, 0.8542, 0.8750, 0.8958, 0.9167, 0.9375, 0.9583,\n",
      "        0.9792, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_vec': tensor(0), 'lcf_cdw_vec': tensor([0.2292, 0.2500, 0.2708, 0.2917, 0.3125, 0.3333, 0.3542, 0.3750, 0.3958,\n",
      "        0.4167, 0.4375, 0.4583, 0.4792, 0.5000, 0.5208, 0.5417, 0.5625, 0.5833,\n",
      "        0.6042, 0.6250, 0.6458, 0.6667, 0.6875, 0.7083, 0.7292, 0.7500, 0.7708,\n",
      "        0.7917, 0.8125, 0.8333, 0.8542, 0.8750, 0.8958, 0.9167, 0.9375, 0.9583,\n",
      "        0.9792, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'lcfs_vec': tensor(0), 'lcfs_cdw_vec': tensor(0), 'lcfs_cdm_vec': tensor(0), 'dlcf_vec': tensor(0), 'dlcfs_vec': tensor(0), 'depend_vec': tensor(0), 'depended_vec': tensor(0), 'spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'text_indices': tensor([  102,   279, 15022,   190, 17244,   125,  6606,   818,   377,   288,\n",
      "          251,   651,   336,   261,  7335,  9878, 11452,  7773,  8025,   245,\n",
      "          818,  1521,  3562,   304,   128,  3004, 25184,   123, 12346,   853,\n",
      "          224,   229,  6606,  4364,   195,   369,  2119, 15598,  2119,   574,\n",
      "         6886,  2829, 30887,  6158, 15105,  1597,   566,   103,  6886,  2829,\n",
      "        30887,  6158, 15105,  1597,   103,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'aspect_bert_indices': tensor(0), 'text_raw_bert_indices': tensor(0), 'polarity': tensor(0), 'cluster_ids': tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100,    0,    0,    0,    0,    0,    0, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100]), 'side_ex_ids': tensor(0), 'left_lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'left_lcf_cdw_vec': tensor([0.2292, 0.2500, 0.2708, 0.2917, 0.3125, 0.3333, 0.3542, 0.3750, 0.3958,\n",
      "        0.4167, 0.4375, 0.4583, 0.4792, 0.5000, 0.5208, 0.5417, 0.5625, 0.5833,\n",
      "        0.6042, 0.6250, 0.6458, 0.6667, 0.6875, 0.7083, 0.7292, 0.7500, 0.7708,\n",
      "        0.7917, 0.8125, 0.8333, 0.8542, 0.8750, 0.8958, 0.9167, 0.9375, 0.9583,\n",
      "        0.9792, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'left_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'left_text_indices': tensor([  102,   279, 15022,   190, 17244,   125,  6606,   818,   377,   288,\n",
      "          251,   651,   336,   261,  7335,  9878, 11452,  7773,  8025,   245,\n",
      "          818,  1521,  3562,   304,   128,  3004, 25184,   123, 12346,   853,\n",
      "          224,   229,  6606,  4364,   195,   369,  2119, 15598,  2119,   574,\n",
      "         6886,  2829, 30887,  6158, 15105,  1597,   566,   103,  6886,  2829,\n",
      "        30887,  6158, 15105,  1597,   103,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'left_dist': tensor(0), 'right_lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'right_lcf_cdw_vec': tensor([0.2292, 0.2500, 0.2708, 0.2917, 0.3125, 0.3333, 0.3542, 0.3750, 0.3958,\n",
      "        0.4167, 0.4375, 0.4583, 0.4792, 0.5000, 0.5208, 0.5417, 0.5625, 0.5833,\n",
      "        0.6042, 0.6250, 0.6458, 0.6667, 0.6875, 0.7083, 0.7292, 0.7500, 0.7708,\n",
      "        0.7917, 0.8125, 0.8333, 0.8542, 0.8750, 0.8958, 0.9167, 0.9375, 0.9583,\n",
      "        0.9792, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'right_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'right_text_indices': tensor([  102,   279, 15022,   190, 17244,   125,  6606,   818,   377,   288,\n",
      "          251,   651,   336,   261,  7335,  9878, 11452,  7773,  8025,   245,\n",
      "          818,  1521,  3562,   304,   128,  3004, 25184,   123, 12346,   853,\n",
      "          224,   229,  6606,  4364,   195,   369,  2119, 15598,  2119,   574,\n",
      "         6886,  2829, 30887,  6158, 15105,  1597,   566,   103,  6886,  2829,\n",
      "        30887,  6158, 15105,  1597,   103,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'right_dist': tensor(0)}]\n",
      "2023-03-23 11:50:02,035 INFO: Load dataset from datasets/apc_datasets/101.news_german_consolidated_with_commented/news_german.valid.dat.apc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preparing dataloader: 100%|██████████| 172/172 [00:00<00:00, 710.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-23 11:50:02,283 INFO: Dataset Label Details: {'neutral': 41, 'negative': 67, 'positive': 61, 'Sum': 169}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-23 11:50:02,400 INFO: valid data examples:\n",
      " [{'ex_id': tensor(0), 'text_raw': 'Die Gruppe fordert ein öffentliches Gespräch mit den Kanzlerkandidat*innen Armin Laschet (CDU), Olaf Scholz (SPD) und Annalena Baerbock (Grüne) noch vor der Bundestagswahl.', 'text_spc': '[CLS] Die Gruppe fordert ein öffentliches Gespräch mit den Kanzlerkandidat*innen Armin Laschet (CDU), Olaf Scholz (SPD) und Annalena Baerbock (Grüne) noch vor der Bundestagswahl. [SEP] Olaf Scholz [SEP]', 'aspect': 'Olaf Scholz', 'aspect_position': tensor(0), 'lca_ids': tensor([0.5581, 0.5814, 0.6047, 0.6279, 0.6512, 0.6744, 0.6977, 0.7209, 0.7442,\n",
      "        0.7674, 0.7907, 0.8140, 0.8372, 0.8605, 0.8837, 0.9070, 0.9302, 0.9535,\n",
      "        0.9767, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.9767, 0.9535, 0.9302, 0.9070, 0.8837, 0.8605, 0.8372, 0.8140, 0.7907,\n",
      "        0.7674, 0.7442, 0.7209, 0.6977, 0.6744, 0.6512, 0.6279, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_vec': tensor(0), 'lcf_cdw_vec': tensor([0.5581, 0.5814, 0.6047, 0.6279, 0.6512, 0.6744, 0.6977, 0.7209, 0.7442,\n",
      "        0.7674, 0.7907, 0.8140, 0.8372, 0.8605, 0.8837, 0.9070, 0.9302, 0.9535,\n",
      "        0.9767, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.9767, 0.9535, 0.9302, 0.9070, 0.8837, 0.8605, 0.8372, 0.8140, 0.7907,\n",
      "        0.7674, 0.7442, 0.7209, 0.6977, 0.6744, 0.6512, 0.6279, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'lcfs_vec': tensor(0), 'lcfs_cdw_vec': tensor(0), 'lcfs_cdm_vec': tensor(0), 'dlcf_vec': tensor(0), 'dlcfs_vec': tensor(0), 'depend_vec': tensor(0), 'depended_vec': tensor(0), 'spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'text_indices': tensor([  102,   229,  2521,  7337,   143,  6265, 30886,  5711,   212,   190,\n",
      "         9848, 21579,  1178, 12197, 16322, 11893,   441, 30885,   201,  4851,\n",
      "         2530,   818, 21042, 19432,   201,  3752,  2530,   136,  6886,  2829,\n",
      "        30887,  6158, 15105,  1597,   201, 16848,  2530,   447,   334,   125,\n",
      "        22417,   566,   103, 21042, 19432,   103,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'aspect_bert_indices': tensor(0), 'text_raw_bert_indices': tensor(0), 'polarity': tensor(1), 'cluster_ids': tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,    1,    1,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100]), 'side_ex_ids': tensor(0), 'left_lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'left_lcf_cdw_vec': tensor([0.5581, 0.5814, 0.6047, 0.6279, 0.6512, 0.6744, 0.6977, 0.7209, 0.7442,\n",
      "        0.7674, 0.7907, 0.8140, 0.8372, 0.8605, 0.8837, 0.9070, 0.9302, 0.9535,\n",
      "        0.9767, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.9767, 0.9535, 0.9302, 0.9070, 0.8837, 0.8605, 0.8372, 0.8140, 0.7907,\n",
      "        0.7674, 0.7442, 0.7209, 0.6977, 0.6744, 0.6512, 0.6279, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'left_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'left_text_indices': tensor([  102,   229,  2521,  7337,   143,  6265, 30886,  5711,   212,   190,\n",
      "         9848, 21579,  1178, 12197, 16322, 11893,   441, 30885,   201,  4851,\n",
      "         2530,   818, 21042, 19432,   201,  3752,  2530,   136,  6886,  2829,\n",
      "        30887,  6158, 15105,  1597,   201, 16848,  2530,   447,   334,   125,\n",
      "        22417,   566,   103, 21042, 19432,   103,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'left_dist': tensor(0), 'right_lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'right_lcf_cdw_vec': tensor([0.5581, 0.5814, 0.6047, 0.6279, 0.6512, 0.6744, 0.6977, 0.7209, 0.7442,\n",
      "        0.7674, 0.7907, 0.8140, 0.8372, 0.8605, 0.8837, 0.9070, 0.9302, 0.9535,\n",
      "        0.9767, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.9767, 0.9535, 0.9302, 0.9070, 0.8837, 0.8605, 0.8372, 0.8140, 0.7907,\n",
      "        0.7674, 0.7442, 0.7209, 0.6977, 0.6744, 0.6512, 0.6279, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'right_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'right_text_indices': tensor([  102,   229,  2521,  7337,   143,  6265, 30886,  5711,   212,   190,\n",
      "         9848, 21579,  1178, 12197, 16322, 11893,   441, 30885,   201,  4851,\n",
      "         2530,   818, 21042, 19432,   201,  3752,  2530,   136,  6886,  2829,\n",
      "        30887,  6158, 15105,  1597,   201, 16848,  2530,   447,   334,   125,\n",
      "        22417,   566,   103, 21042, 19432,   103,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'right_dist': tensor(0)}, {'ex_id': tensor(1), 'text_raw': 'Der begann am Freitagabend, als Armin Laschet sich zuschalten ließ in eine Programmkonferenz der CSU.', 'text_spc': '[CLS] Der begann am Freitagabend, als Armin Laschet sich zuschalten ließ in eine Programmkonferenz der CSU. [SEP] Armin Laschet [SEP]', 'aspect': 'Armin Laschet', 'aspect_position': tensor(0), 'lca_ids': tensor([0.8400, 0.8800, 0.9200, 0.9600, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9600, 0.9200, 0.8800, 0.8400,\n",
      "        0.8000, 0.7600, 0.7200, 0.6800, 0.6400, 0.6000, 0.5600, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_vec': tensor(0), 'lcf_cdw_vec': tensor([0.8400, 0.8800, 0.9200, 0.9600, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9600, 0.9200, 0.8800, 0.8400,\n",
      "        0.8000, 0.7600, 0.7200, 0.6800, 0.6400, 0.6000, 0.5600, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_cdm_vec': tensor([0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'lcfs_vec': tensor(0), 'lcfs_cdw_vec': tensor(0), 'lcfs_cdm_vec': tensor(0), 'dlcf_vec': tensor(0), 'dlcfs_vec': tensor(0), 'depend_vec': tensor(0), 'depended_vec': tensor(0), 'spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'text_indices': tensor([  102,   351,  2393,   339, 18861,   818,   276, 16322, 11893,   441,\n",
      "        30885,   251, 11725, 19826,   547,   106,  3412,   153,   261,  2246,\n",
      "         8413,   125,  7336,   566,   103, 16322, 11893,   441, 30885,   103,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'aspect_bert_indices': tensor(0), 'text_raw_bert_indices': tensor(0), 'polarity': tensor(1), 'cluster_ids': tensor([-100, -100, -100, -100, -100, -100, -100,    1,    1,    1,    1, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100]), 'side_ex_ids': tensor(0), 'left_lcf_cdm_vec': tensor([0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'left_lcf_cdw_vec': tensor([0.8400, 0.8800, 0.9200, 0.9600, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9600, 0.9200, 0.8800, 0.8400,\n",
      "        0.8000, 0.7600, 0.7200, 0.6800, 0.6400, 0.6000, 0.5600, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'left_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'left_text_indices': tensor([  102,   351,  2393,   339, 18861,   818,   276, 16322, 11893,   441,\n",
      "        30885,   251, 11725, 19826,   547,   106,  3412,   153,   261,  2246,\n",
      "         8413,   125,  7336,   566,   103, 16322, 11893,   441, 30885,   103,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'left_dist': tensor(0), 'right_lcf_cdm_vec': tensor([0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'right_lcf_cdw_vec': tensor([0.8400, 0.8800, 0.9200, 0.9600, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9600, 0.9200, 0.8800, 0.8400,\n",
      "        0.8000, 0.7600, 0.7200, 0.6800, 0.6400, 0.6000, 0.5600, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'right_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'right_text_indices': tensor([  102,   351,  2393,   339, 18861,   818,   276, 16322, 11893,   441,\n",
      "        30885,   251, 11725, 19826,   547,   106,  3412,   153,   261,  2246,\n",
      "         8413,   125,  7336,   566,   103, 16322, 11893,   441, 30885,   103,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'right_dist': tensor(0)}]\n",
      "[2023-03-23 11:50:02] (2.0.28) \u001b[31mCaching dataset... please remove cached dataset if any problem happens.\u001b[0m\n",
      "2023-03-23 11:50:06,232 INFO: Model Architecture:\n",
      " APCEnsembler(\n",
      "  (models): ModuleList(\n",
      "    (0): FAST_LSA_T_V2(\n",
      "      (bert4global): BertModel(\n",
      "        (embeddings): BertEmbeddings(\n",
      "          (word_embeddings): Embedding(31102, 768, padding_idx=0)\n",
      "          (position_embeddings): Embedding(512, 768)\n",
      "          (token_type_embeddings): Embedding(2, 768)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (encoder): BertEncoder(\n",
      "          (layer): ModuleList(\n",
      "            (0): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (1): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (2): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (3): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (4): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (5): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (6): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (7): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (8): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (9): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (10): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (11): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (pooler): BertPooler(\n",
      "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (activation): Tanh()\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0, inplace=False)\n",
      "      (post_encoder): Encoder(\n",
      "        (encoder): ModuleList(\n",
      "          (0): SelfAttention(\n",
      "            (SA): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (tanh): Tanh()\n",
      "      )\n",
      "      (post_encoder_): Encoder(\n",
      "        (encoder): ModuleList(\n",
      "          (0): SelfAttention(\n",
      "            (SA): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (tanh): Tanh()\n",
      "      )\n",
      "      (bert_pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "      (CDW_LSA): LSA(\n",
      "        (encoder): Encoder(\n",
      "          (encoder): ModuleList(\n",
      "            (0): SelfAttention(\n",
      "              (SA): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (tanh): Tanh()\n",
      "        )\n",
      "        (encoder_left): Encoder(\n",
      "          (encoder): ModuleList(\n",
      "            (0): SelfAttention(\n",
      "              (SA): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (tanh): Tanh()\n",
      "        )\n",
      "        (encoder_right): Encoder(\n",
      "          (encoder): ModuleList(\n",
      "            (0): SelfAttention(\n",
      "              (SA): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (tanh): Tanh()\n",
      "        )\n",
      "        (linear_window_3h): Linear(in_features=2304, out_features=768, bias=True)\n",
      "        (linear_window_2h): Linear(in_features=1536, out_features=768, bias=True)\n",
      "      )\n",
      "      (post_linear): Linear(in_features=1536, out_features=768, bias=True)\n",
      "      (dense): Linear(in_features=768, out_features=3, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(31102, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dense): Linear(in_features=3, out_features=3, bias=True)\n",
      ")\n",
      "2023-03-23 11:50:06,233 INFO: ABSADatasetsVersion:None\t-->\tCalling Count:0\n",
      "2023-03-23 11:50:06,234 INFO: MV:<metric_visualizer.metric_visualizer.MetricVisualizer object at 0x7f6c510ef7f0>\t-->\tCalling Count:4\n",
      "2023-03-23 11:50:06,234 INFO: PyABSAVersion:2.0.28\t-->\tCalling Count:2\n",
      "2023-03-23 11:50:06,235 INFO: SRD:3\t-->\tCalling Count:6740\n",
      "2023-03-23 11:50:06,237 INFO: TorchVersion:1.12.1+cudaNone\t-->\tCalling Count:2\n",
      "2023-03-23 11:50:06,238 INFO: TransformersVersion:4.24.0\t-->\tCalling Count:2\n",
      "2023-03-23 11:50:06,242 INFO: auto_device:True\t-->\tCalling Count:182\n",
      "2023-03-23 11:50:06,244 INFO: batch_size:16\t-->\tCalling Count:8\n",
      "2023-03-23 11:50:06,245 INFO: cache_dataset:True\t-->\tCalling Count:2\n",
      "2023-03-23 11:50:06,247 INFO: checkpoint_save_mode:1\t-->\tCalling Count:7\n",
      "2023-03-23 11:50:06,248 INFO: cross_validate_fold:-1\t-->\tCalling Count:2\n",
      "2023-03-23 11:50:06,249 INFO: dataset_file:{'train': ['datasets/apc_datasets/101.news_german_consolidated_with_commented/news_german.train.dat.apc'], 'test': ['datasets/apc_datasets/101.news_german_consolidated_with_commented/news_german.test.dat.apc'], 'valid': ['datasets/apc_datasets/101.news_german_consolidated_with_commented/news_german.valid.dat.apc']}\t-->\tCalling Count:30\n",
      "2023-03-23 11:50:06,250 INFO: dataset_name:custom_dataset\t-->\tCalling Count:13\n",
      "2023-03-23 11:50:06,251 INFO: dca_layer:3\t-->\tCalling Count:0\n",
      "2023-03-23 11:50:06,252 INFO: dca_p:1\t-->\tCalling Count:0\n",
      "2023-03-23 11:50:06,254 INFO: deep_ensemble:False\t-->\tCalling Count:0\n",
      "2023-03-23 11:50:06,255 INFO: device:cpu\t-->\tCalling Count:4046\n",
      "2023-03-23 11:50:06,256 INFO: device_name:Unknown\t-->\tCalling Count:2\n",
      "2023-03-23 11:50:06,257 INFO: dlcf_a:2\t-->\tCalling Count:0\n",
      "2023-03-23 11:50:06,258 INFO: dropout:0\t-->\tCalling Count:2\n",
      "2023-03-23 11:50:06,260 INFO: dynamic_truncate:True\t-->\tCalling Count:6740\n",
      "2023-03-23 11:50:06,261 INFO: embed_dim:768\t-->\tCalling Count:14\n",
      "2023-03-23 11:50:06,262 INFO: ensemble_mode:cat\t-->\tCalling Count:0\n",
      "2023-03-23 11:50:06,263 INFO: eta:1\t-->\tCalling Count:452\n",
      "2023-03-23 11:50:06,263 INFO: eta_lr:0.1\t-->\tCalling Count:2\n",
      "2023-03-23 11:50:06,264 INFO: evaluate_begin:0\t-->\tCalling Count:18\n",
      "2023-03-23 11:50:06,265 INFO: from_checkpoint:None\t-->\tCalling Count:2\n",
      "2023-03-23 11:50:06,266 INFO: hidden_dim:768\t-->\tCalling Count:0\n",
      "2023-03-23 11:50:06,268 INFO: index_to_label:{0: 'negative', 1: 'neutral', 2: 'positive'}\t-->\tCalling Count:6\n",
      "2023-03-23 11:50:06,269 INFO: inference_model:None\t-->\tCalling Count:0\n",
      "2023-03-23 11:50:06,270 INFO: initializer:xavier_uniform_\t-->\tCalling Count:0\n",
      "2023-03-23 11:50:06,272 INFO: inputs_cols:['lcf_cdm_vec', 'lcf_cdw_vec', 'left_lcf_cdm_vec', 'left_lcf_cdw_vec', 'right_lcf_cdm_vec', 'right_lcf_cdw_vec', 'spc_mask_vec', 'text_indices']\t-->\tCalling Count:51010\n",
      "2023-03-23 11:50:06,273 INFO: l2reg:1e-06\t-->\tCalling Count:4\n",
      "2023-03-23 11:50:06,275 INFO: label_to_index:{'negative': 0, 'neutral': 1, 'positive': 2}\t-->\tCalling Count:0\n",
      "2023-03-23 11:50:06,277 INFO: lcf:cdw\t-->\tCalling Count:454\n",
      "2023-03-23 11:50:06,278 INFO: learning_rate:2e-05\t-->\tCalling Count:2\n",
      "2023-03-23 11:50:06,280 INFO: load_aug:False\t-->\tCalling Count:2\n",
      "2023-03-23 11:50:06,281 INFO: log_step:10\t-->\tCalling Count:177\n",
      "2023-03-23 11:50:06,282 INFO: logger:<Logger fast_lsa_t_v2 (INFO)>\t-->\tCalling Count:40\n",
      "2023-03-23 11:50:06,283 INFO: loss:0.0020614192355424164\t-->\tCalling Count:0\n",
      "2023-03-23 11:50:06,284 INFO: lsa:False\t-->\tCalling Count:0\n",
      "2023-03-23 11:50:06,286 INFO: max_seq_len:80\t-->\tCalling Count:42232\n",
      "2023-03-23 11:50:06,287 INFO: max_test_metrics:{'max_apc_test_acc': 0.5739644970414202, 'max_apc_test_f1': 0.578071827402782}\t-->\tCalling Count:28\n",
      "2023-03-23 11:50:06,288 INFO: metrics_of_this_checkpoint:{'acc': 0.5207100591715976, 'f1': 0.5246438273314933}\t-->\tCalling Count:34\n",
      "2023-03-23 11:50:06,289 INFO: model:<class 'pyabsa.tasks.AspectPolarityClassification.models.__lcf__.fast_lsa_t_v2.FAST_LSA_T_V2'>\t-->\tCalling Count:8\n",
      "2023-03-23 11:50:06,290 INFO: model_name:fast_lsa_t_v2\t-->\tCalling Count:6787\n",
      "2023-03-23 11:50:06,291 INFO: model_path_to_save:/home/steffen/thesis/mv_heckpoints/\t-->\tCalling Count:25\n",
      "2023-03-23 11:50:06,293 INFO: num_epoch:20\t-->\tCalling Count:2\n",
      "2023-03-23 11:50:06,294 INFO: optimizer:adamw\t-->\tCalling Count:2\n",
      "2023-03-23 11:50:06,295 INFO: output_dim:3\t-->\tCalling Count:24\n",
      "2023-03-23 11:50:06,296 INFO: overwrite_cache:False\t-->\tCalling Count:2\n",
      "2023-03-23 11:50:06,297 INFO: path_to_save:/home/steffen/thesis/mv_heckpoints/\t-->\tCalling Count:4\n",
      "2023-03-23 11:50:06,298 INFO: patience:5\t-->\tCalling Count:13\n",
      "2023-03-23 11:50:06,299 INFO: pretrained_bert:bert-base-german-dbmdz-cased\t-->\tCalling Count:12\n",
      "2023-03-23 11:50:06,300 INFO: save_mode:1\t-->\tCalling Count:16\n",
      "2023-03-23 11:50:06,301 INFO: seed:52\t-->\tCalling Count:13\n",
      "2023-03-23 11:50:06,302 INFO: sigma:0.3\t-->\tCalling Count:0\n",
      "2023-03-23 11:50:06,303 INFO: similarity_threshold:1\t-->\tCalling Count:6\n",
      "2023-03-23 11:50:06,304 INFO: spacy_model:de_core_news_sm\t-->\tCalling Count:12\n",
      "2023-03-23 11:50:06,305 INFO: srd_alignment:True\t-->\tCalling Count:0\n",
      "2023-03-23 11:50:06,307 INFO: task_code:APC\t-->\tCalling Count:2\n",
      "2023-03-23 11:50:06,308 INFO: task_name:Aspect-based Sentiment Classification\t-->\tCalling Count:1\n",
      "2023-03-23 11:50:06,310 INFO: tokenizer:PreTrainedTokenizerFast(name_or_path='bert-base-german-dbmdz-cased', vocab_size=31102, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\t-->\tCalling Count:0\n",
      "2023-03-23 11:50:06,311 INFO: use_amp:False\t-->\tCalling Count:354\n",
      "2023-03-23 11:50:06,312 INFO: use_bert_spc:True\t-->\tCalling Count:0\n",
      "2023-03-23 11:50:06,313 INFO: use_syntax_based_SRD:False\t-->\tCalling Count:0\n",
      "2023-03-23 11:50:06,314 INFO: warmup_step:-1\t-->\tCalling Count:177\n",
      "2023-03-23 11:50:06,315 INFO: window:lr\t-->\tCalling Count:448\n",
      "2023-03-23 11:50:06,322 INFO: ***** Running training for Aspect-based Sentiment Classification *****\n",
      "2023-03-23 11:50:06,323 INFO: Training set examples = 169\n",
      "2023-03-23 11:50:06,324 INFO: Test set examples = 1347\n",
      "2023-03-23 11:50:06,325 INFO: Total params = 123510545, Trainable params = 123510545, Non-trainable params = 0\n",
      "2023-03-23 11:50:06,326 INFO: Batch size = 16\n",
      "2023-03-23 11:50:06,327 INFO: Num steps = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Smooth Loss: 1.0756: 100%|██████████| 11/11 [01:39<00:00,  9.01s/it, Dev Acc:39.64(max:39.64) Dev F1:18.93(max:18.93)]\n",
      "Epoch:  1 | Smooth Loss: 1.0621: 100%|██████████| 11/11 [01:39<00:00,  9.08s/it, Dev Acc:39.64(max:39.64) Dev F1:18.93(max:18.93)]\n",
      "Epoch:  2 | Smooth Loss: 1.0492: 100%|██████████| 11/11 [01:34<00:00,  8.60s/it, Dev Acc:36.09(max:39.64) Dev F1:27.07(max:27.07)]\n",
      "Epoch:  3 | Smooth Loss: 1.0359: 100%|██████████| 11/11 [01:40<00:00,  9.16s/it, Dev Acc:34.32(max:39.64) Dev F1:26.03(max:27.07)]\n",
      "Epoch:  4 | Smooth Loss: 1.0187: 100%|██████████| 11/11 [01:42<00:00,  9.31s/it, Dev Acc:35.50(max:39.64) Dev F1:26.99(max:27.07)]\n",
      "Epoch:  5 | Smooth Loss: 0.9969: 100%|██████████| 11/11 [01:47<00:00,  9.74s/it, Dev Acc:35.50(max:39.64) Dev F1:26.90(max:27.07)]\n",
      "Epoch:  6 | Smooth Loss: 0.9751: 100%|██████████| 11/11 [01:57<00:00, 10.72s/it, Dev Acc:36.09(max:39.64) Dev F1:27.69(max:27.69)]\n",
      "Epoch:  7 | Smooth Loss: 0.9632: 100%|██████████| 11/11 [01:46<00:00,  9.66s/it, Dev Acc:40.83(max:40.83) Dev F1:41.16(max:41.16)]\n",
      "Epoch:  8 | Smooth Loss: 0.9333: 100%|██████████| 11/11 [01:38<00:00,  8.95s/it, Dev Acc:47.93(max:47.93) Dev F1:43.36(max:43.36)]\n",
      "Epoch:  9 | Smooth Loss: 0.8829: 100%|██████████| 11/11 [02:14<00:00, 12.27s/it, Dev Acc:42.60(max:47.93) Dev F1:40.96(max:45.27)]\n",
      "Epoch: 10 | Smooth Loss: 0.8151: 100%|██████████| 11/11 [01:32<00:00,  8.38s/it, Dev Acc:44.97(max:47.93) Dev F1:42.67(max:45.27)]\n",
      "Epoch: 11 | Smooth Loss: 0.7550: 100%|██████████| 11/11 [01:31<00:00,  8.32s/it, Dev Acc:44.97(max:47.93) Dev F1:43.85(max:45.27)]\n",
      "Epoch: 12 | Smooth Loss: 0.7037: 100%|██████████| 11/11 [01:37<00:00,  8.88s/it, Dev Acc:52.07(max:52.07) Dev F1:52.71(max:52.71)]\n",
      "Epoch: 13 | Smooth Loss: 0.6569: 100%|██████████| 11/11 [01:22<00:00,  7.46s/it, Dev Acc:45.56(max:52.07) Dev F1:45.23(max:52.71)]\n",
      "Epoch: 14 | Smooth Loss: 0.6151: 100%|██████████| 11/11 [01:21<00:00,  7.36s/it, Dev Acc:51.48(max:52.07) Dev F1:51.02(max:52.71)]\n",
      "Epoch: 15 | Smooth Loss: 0.5783: 100%|██████████| 11/11 [01:20<00:00,  7.29s/it, Dev Acc:48.52(max:52.07) Dev F1:48.33(max:52.71)]\n",
      "Epoch: 16 | Smooth Loss: 0.5449: 100%|██████████| 11/11 [01:19<00:00,  7.24s/it, Dev Acc:47.93(max:52.07) Dev F1:47.44(max:52.71)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-03-23 12:17:52] (2.0.28) Loading best model: /home/steffen/thesis/mv_heckpoints//fast_lsa_t_v2_custom_dataset_acc_52.07_f1_52.71/ and evaluating on test set \n",
      "2023-03-23 12:20:22,173 INFO: \n",
      "------------------------------------------------------ Metrics Table ------------------------------------------------------\n",
      "╒═════════════════════════════════════════════════════════════╤══════════════════════════════╤═════════════════════════════╕\n",
      "│ Trial                                                       │ average-Max-Test-Acc (std)   │ average-Max-Test-F1 (std)   │\n",
      "╞═════════════════════════════════════════════════════════════╪══════════════════════════════╪═════════════════════════════╡\n",
      "│ fast_lsa_t_v2-custom_dataset-bert-base-german-dbmdz-uncased │ 61.32 (0.0)                  │ 57.99 (0.0)                 │\n",
      "├─────────────────────────────────────────────────────────────┼──────────────────────────────┼─────────────────────────────┤\n",
      "│ fast_lsa_t_v2-custom_dataset-bert-base-german-dbmdz-cased   │ 58.57 (0.0)                  │ 55.11 (0.0)                 │\n",
      "╘═════════════════════════════════════════════════════════════╧══════════════════════════════╧═════════════════════════════╛\n",
      "------------------------------------- https://github.com/yangheng95/metric_visualizer -------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steffen/.conda/envs/thesis/lib/python3.10/site-packages/metric_visualizer/utils.py:25: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  self.skewness = stats.skew(self.data, keepdims=True)\n",
      "/home/steffen/.conda/envs/thesis/lib/python3.10/site-packages/pyabsa/framework/trainer_class/trainer_template.py:228: ResourceWarning: unclosed file <_io.TextIOWrapper name='/home/steffen/Nextcloud/uni/22-ws/thesis-personalities/code/logs/fast_lsa_t_v2_20230323 111747/trainer.log' mode='a' encoding='utf8'>\n",
      "  self.config.logger.removeHandler(self.config.logger.handlers[0])\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "for ptm in [\"bert-base-german-dbmdz-uncased\", \"bert-base-german-dbmdz-cased\"]:\n",
    "    config.pretrained_bert = ptm\n",
    "    trainer = APC.APCTrainer(\n",
    "        config=config,\n",
    "        dataset=dataset,\n",
    "        auto_device=DeviceTypeOption.AUTO,\n",
    "        path_to_save=checkpoint_path,\n",
    "        checkpoint_save_mode=ModelSaveOption.SAVE_MODEL_STATE_DICT\n",
    "    )\n",
    "    config.MV.next_trial()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-03-23 12:20:27] (2.0.28) Set Model Device: cpu\n",
      "[2023-03-23 12:20:27] (2.0.28) Device Name: Unknown\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2023-03-23 12:20:27,842 INFO: PyABSA version: 2.0.28\n",
      "2023-03-23 12:20:27,844 INFO: Transformers version: 4.24.0\n",
      "2023-03-23 12:20:27,845 INFO: Torch version: 1.12.1+cudaNone\n",
      "2023-03-23 12:20:27,847 INFO: Device: Unknown\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2023-03-23 12:20:27,921 INFO: Searching dataset 101.news_german_consolidated_with_commented in local disk\n",
      "2023-03-23 12:20:27,960 INFO: You can set load_aug=True in a trainer to augment your dataset (English only yet) and improve performance.\n",
      "2023-03-23 12:20:27,961 INFO: Please use a new folder to perform new text augment if the former augment in datasets/apc_datasets/101.news_german_consolidated_with_commented errored unexpectedly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steffen/.conda/envs/thesis/lib/python3.10/multiprocessing/pool.py:268: ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.Pool state=RUN pool_size=1>\n",
      "  _warn(f\"unclosed running multiprocessing pool {self!r}\",\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/steffen/.conda/envs/thesis/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:446: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/mdeberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-23 12:20:36,415 INFO: Load dataset from datasets/apc_datasets/101.news_german_consolidated_with_commented/news_german.train.dat.apc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preparing dataloader: 100%|██████████| 172/172 [00:00<00:00, 913.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-23 12:20:36,614 INFO: Dataset Label Details: {'neutral': 34, 'negative': 71, 'positive': 64, 'Sum': 169}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-23 12:20:36,705 INFO: train data examples:\n",
      " [{'ex_id': tensor(0), 'text_raw': 'Klimaschutz ist für Annalena Baerbock vor allem ein Kampf gegen die Autofahrer , behauptete Blume in der Augsburger Allgemeinen.', 'text_spc': '[CLS] Klimaschutz ist für Annalena Baerbock vor allem ein Kampf gegen die Autofahrer , behauptete Blume in der Augsburger Allgemeinen. [SEP] Annalena Baerbock [SEP]', 'aspect': 'Annalena Baerbock', 'aspect_position': tensor(0), 'lca_ids': tensor([0.9429, 0.9714, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9714, 0.9429, 0.9143, 0.8857, 0.8571,\n",
      "        0.8286, 0.8000, 0.7714, 0.7429, 0.7143, 0.6857, 0.6571, 0.6286, 0.6000,\n",
      "        0.5714, 0.5429, 0.5143, 0.4857, 0.4571, 0.4286, 0.4000, 0.3714, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_vec': tensor(0), 'lcf_cdw_vec': tensor([0.9429, 0.9714, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9714, 0.9429, 0.9143, 0.8857, 0.8571,\n",
      "        0.8286, 0.8000, 0.7714, 0.7429, 0.7143, 0.6857, 0.6571, 0.6286, 0.6000,\n",
      "        0.5714, 0.5429, 0.5143, 0.4857, 0.4571, 0.4286, 0.4000, 0.3714, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_cdm_vec': tensor([0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'lcfs_vec': tensor(0), 'lcfs_cdw_vec': tensor(0), 'lcfs_cdm_vec': tensor(0), 'dlcf_vec': tensor(0), 'dlcfs_vec': tensor(0), 'depend_vec': tensor(0), 'depended_vec': tensor(0), 'spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'text_indices': tensor([     1,  34030,  21486,    857,    957,   7470,  85727,   2216,    296,\n",
      "        165464,   1498,    260,  36893,    889,  57900,   9059,    399,   3196,\n",
      "         91291,    260,    262,    391,  33820,   6341, 173736,    266,    282,\n",
      "           443,    260, 118765,    296,  91151,    279,    261,      2,   7470,\n",
      "         85727,   2216,    296, 165464,      2,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0]), 'aspect_bert_indices': tensor(0), 'text_raw_bert_indices': tensor(0), 'polarity': tensor(0), 'cluster_ids': tensor([-100, -100, -100, -100, -100,    0,    0,    0,    0,    0, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100]), 'side_ex_ids': tensor(0), 'left_lcf_cdm_vec': tensor([0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'left_lcf_cdw_vec': tensor([0.9429, 0.9714, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9714, 0.9429, 0.9143, 0.8857, 0.8571,\n",
      "        0.8286, 0.8000, 0.7714, 0.7429, 0.7143, 0.6857, 0.6571, 0.6286, 0.6000,\n",
      "        0.5714, 0.5429, 0.5143, 0.4857, 0.4571, 0.4286, 0.4000, 0.3714, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'left_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'left_text_indices': tensor([     1,  34030,  21486,    857,    957,   7470,  85727,   2216,    296,\n",
      "        165464,   1498,    260,  36893,    889,  57900,   9059,    399,   3196,\n",
      "         91291,    260,    262,    391,  33820,   6341, 173736,    266,    282,\n",
      "           443,    260, 118765,    296,  91151,    279,    261,      2,   7470,\n",
      "         85727,   2216,    296, 165464,      2,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0]), 'left_dist': tensor(0), 'right_lcf_cdm_vec': tensor([0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'right_lcf_cdw_vec': tensor([0.9429, 0.9714, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9714, 0.9429, 0.9143, 0.8857, 0.8571,\n",
      "        0.8286, 0.8000, 0.7714, 0.7429, 0.7143, 0.6857, 0.6571, 0.6286, 0.6000,\n",
      "        0.5714, 0.5429, 0.5143, 0.4857, 0.4571, 0.4286, 0.4000, 0.3714, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'right_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'right_text_indices': tensor([     1,  34030,  21486,    857,    957,   7470,  85727,   2216,    296,\n",
      "        165464,   1498,    260,  36893,    889,  57900,   9059,    399,   3196,\n",
      "         91291,    260,    262,    391,  33820,   6341, 173736,    266,    282,\n",
      "           443,    260, 118765,    296,  91151,    279,    261,      2,   7470,\n",
      "         85727,   2216,    296, 165464,      2,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0]), 'right_dist': tensor(0)}, {'ex_id': tensor(1), 'text_raw': 'Nun habe Armin Laschet ein Problem, heißt es in einem Blogeintrag Webers von Montag.', 'text_spc': '[CLS] Nun habe Armin Laschet ein Problem, heißt es in einem Blogeintrag Webers von Montag. [SEP] Armin Laschet [SEP]', 'aspect': 'Armin Laschet', 'aspect_position': tensor(0), 'lca_ids': tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9615, 0.9231, 0.8846, 0.8462, 0.8077, 0.7692, 0.7308,\n",
      "        0.6923, 0.6538, 0.6154, 0.5769, 0.5385, 0.5000, 0.4615, 0.4231, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_vec': tensor(0), 'lcf_cdw_vec': tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9615, 0.9231, 0.8846, 0.8462, 0.8077, 0.7692, 0.7308,\n",
      "        0.6923, 0.6538, 0.6154, 0.5769, 0.5385, 0.5000, 0.4615, 0.4231, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_cdm_vec': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'lcfs_vec': tensor(0), 'lcfs_cdw_vec': tensor(0), 'lcfs_cdm_vec': tensor(0), 'dlcf_vec': tensor(0), 'dlcfs_vec': tensor(0), 'depend_vec': tensor(0), 'depended_vec': tensor(0), 'spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'text_indices': tensor([     1,  21191,   6248,  17514,    349,    502,   5924,    271,    889,\n",
      "         11827,    262,  12679,  40255,    656,    282,    260,   2787,   4627,\n",
      "        199797,    941,  91984,    264,    796,  54872,    261,      2,  17514,\n",
      "           349,    502,   5924,    271,      2,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0]), 'aspect_bert_indices': tensor(0), 'text_raw_bert_indices': tensor(0), 'polarity': tensor(0), 'cluster_ids': tensor([-100, -100, -100,    0,    0,    0,    0,    0, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100]), 'side_ex_ids': tensor(0), 'left_lcf_cdm_vec': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'left_lcf_cdw_vec': tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9615, 0.9231, 0.8846, 0.8462, 0.8077, 0.7692, 0.7308,\n",
      "        0.6923, 0.6538, 0.6154, 0.5769, 0.5385, 0.5000, 0.4615, 0.4231, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'left_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'left_text_indices': tensor([     1,  21191,   6248,  17514,    349,    502,   5924,    271,    889,\n",
      "         11827,    262,  12679,  40255,    656,    282,    260,   2787,   4627,\n",
      "        199797,    941,  91984,    264,    796,  54872,    261,      2,  17514,\n",
      "           349,    502,   5924,    271,      2,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0]), 'left_dist': tensor(0), 'right_lcf_cdm_vec': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'right_lcf_cdw_vec': tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9615, 0.9231, 0.8846, 0.8462, 0.8077, 0.7692, 0.7308,\n",
      "        0.6923, 0.6538, 0.6154, 0.5769, 0.5385, 0.5000, 0.4615, 0.4231, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'right_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'right_text_indices': tensor([     1,  21191,   6248,  17514,    349,    502,   5924,    271,    889,\n",
      "         11827,    262,  12679,  40255,    656,    282,    260,   2787,   4627,\n",
      "        199797,    941,  91984,    264,    796,  54872,    261,      2,  17514,\n",
      "           349,    502,   5924,    271,      2,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0]), 'right_dist': tensor(0)}]\n",
      "2023-03-23 12:20:37,616 INFO: Load dataset from datasets/apc_datasets/101.news_german_consolidated_with_commented/news_german.test.dat.apc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preparing dataloader: 100%|██████████| 1367/1367 [00:01<00:00, 1172.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-23 12:20:38,795 INFO: Dataset Label Details: {'neutral': 276, 'negative': 548, 'positive': 523, 'Sum': 1347}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-23 12:20:39,409 INFO: test data examples:\n",
      " [{'ex_id': tensor(0), 'text_raw': 'Noch vier Wochen bis zur Bundestagswahl: Umfragen sehen die SPD mit Kanzlerkandidat Olaf Scholz als stärkste Kraft - deutlich vor der Union.', 'text_spc': '[CLS] Noch vier Wochen bis zur Bundestagswahl: Umfragen sehen die SPD mit Kanzlerkandidat Olaf Scholz als stärkste Kraft - deutlich vor der Union. [SEP] Olaf Scholz [SEP]', 'aspect': 'Olaf Scholz', 'aspect_position': tensor(0), 'lca_ids': tensor([0.5366, 0.5610, 0.5854, 0.6098, 0.6341, 0.6585, 0.6829, 0.7073, 0.7317,\n",
      "        0.7561, 0.7805, 0.8049, 0.8293, 0.8537, 0.8780, 0.9024, 0.9268, 0.9512,\n",
      "        0.9756, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9756, 0.9512, 0.9268, 0.9024, 0.8780, 0.8537, 0.8293,\n",
      "        0.8049, 0.7805, 0.7561, 0.7317, 0.7073, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_vec': tensor(0), 'lcf_cdw_vec': tensor([0.5366, 0.5610, 0.5854, 0.6098, 0.6341, 0.6585, 0.6829, 0.7073, 0.7317,\n",
      "        0.7561, 0.7805, 0.8049, 0.8293, 0.8537, 0.8780, 0.9024, 0.9268, 0.9512,\n",
      "        0.9756, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9756, 0.9512, 0.9268, 0.9024, 0.8780, 0.8537, 0.8293,\n",
      "        0.8049, 0.7805, 0.7561, 0.7317, 0.7073, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'lcfs_vec': tensor(0), 'lcfs_cdw_vec': tensor(0), 'lcfs_cdm_vec': tensor(0), 'dlcf_vec': tensor(0), 'dlcfs_vec': tensor(0), 'depend_vec': tensor(0), 'depended_vec': tensor(0), 'spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'text_indices': tensor([     1,    260, 120028,  11964,  47039,   1582,   3891,    260, 165566,\n",
      "           264,  71898,    268,   3049,  56588,    260,  14506,    399,  86475,\n",
      "           750,   4228, 121359, 163918,  26164,    368, 125030,    361,   1228,\n",
      "           260,  72190,   1083,  47389,    260,    265,    270,    274,  11049,\n",
      "          1498,    443,  16866,    261,      2,  26164,    368, 125030,    361,\n",
      "             2,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0]), 'aspect_bert_indices': tensor(0), 'text_raw_bert_indices': tensor(0), 'polarity': tensor(2), 'cluster_ids': tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,    2,    2,\n",
      "           2,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100]), 'side_ex_ids': tensor(0), 'left_lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'left_lcf_cdw_vec': tensor([0.5366, 0.5610, 0.5854, 0.6098, 0.6341, 0.6585, 0.6829, 0.7073, 0.7317,\n",
      "        0.7561, 0.7805, 0.8049, 0.8293, 0.8537, 0.8780, 0.9024, 0.9268, 0.9512,\n",
      "        0.9756, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9756, 0.9512, 0.9268, 0.9024, 0.8780, 0.8537, 0.8293,\n",
      "        0.8049, 0.7805, 0.7561, 0.7317, 0.7073, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'left_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'left_text_indices': tensor([     1,    260, 120028,  11964,  47039,   1582,   3891,    260, 165566,\n",
      "           264,  71898,    268,   3049,  56588,    260,  14506,    399,  86475,\n",
      "           750,   4228, 121359, 163918,  26164,    368, 125030,    361,   1228,\n",
      "           260,  72190,   1083,  47389,    260,    265,    270,    274,  11049,\n",
      "          1498,    443,  16866,    261,      2,  26164,    368, 125030,    361,\n",
      "             2,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0]), 'left_dist': tensor(0), 'right_lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'right_lcf_cdw_vec': tensor([0.5366, 0.5610, 0.5854, 0.6098, 0.6341, 0.6585, 0.6829, 0.7073, 0.7317,\n",
      "        0.7561, 0.7805, 0.8049, 0.8293, 0.8537, 0.8780, 0.9024, 0.9268, 0.9512,\n",
      "        0.9756, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9756, 0.9512, 0.9268, 0.9024, 0.8780, 0.8537, 0.8293,\n",
      "        0.8049, 0.7805, 0.7561, 0.7317, 0.7073, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'right_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'right_text_indices': tensor([     1,    260, 120028,  11964,  47039,   1582,   3891,    260, 165566,\n",
      "           264,  71898,    268,   3049,  56588,    260,  14506,    399,  86475,\n",
      "           750,   4228, 121359, 163918,  26164,    368, 125030,    361,   1228,\n",
      "           260,  72190,   1083,  47389,    260,    265,    270,    274,  11049,\n",
      "          1498,    443,  16866,    261,      2,  26164,    368, 125030,    361,\n",
      "             2,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0]), 'right_dist': tensor(0)}, {'ex_id': tensor(1), 'text_raw': 'Er kritisierte den Vorwurf der Grünen, dass es sich hier um eine Rufmordkampagne handle, weil Medien über die Plagiate berichten: \"Die Grünen sprechen von einer \\'Kampagne\\' gegen Annalena Baerbock .', 'text_spc': '[CLS] Er kritisierte den Vorwurf der Grünen, dass es sich hier um eine Rufmordkampagne handle, weil Medien über die Plagiate berichten: \"Die Grünen sprechen von einer \\'Kampagne\\' gegen Annalena Baerbock . [SEP] Annalena Baerbock [SEP]', 'aspect': 'Annalena Baerbock', 'aspect_position': tensor(0), 'lca_ids': tensor([0.2000, 0.2182, 0.2364, 0.2545, 0.2727, 0.2909, 0.3091, 0.3273, 0.3455,\n",
      "        0.3636, 0.3818, 0.4000, 0.4182, 0.4364, 0.4545, 0.4727, 0.4909, 0.5091,\n",
      "        0.5273, 0.5455, 0.5636, 0.5818, 0.6000, 0.6182, 0.6364, 0.6545, 0.6727,\n",
      "        0.6909, 0.7091, 0.7273, 0.7455, 0.7636, 0.7818, 0.8000, 0.8182, 0.8364,\n",
      "        0.8545, 0.8727, 0.8909, 0.9091, 0.9273, 0.9455, 0.9636, 0.9818, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_vec': tensor(0), 'lcf_cdw_vec': tensor([0.2000, 0.2182, 0.2364, 0.2545, 0.2727, 0.2909, 0.3091, 0.3273, 0.3455,\n",
      "        0.3636, 0.3818, 0.4000, 0.4182, 0.4364, 0.4545, 0.4727, 0.4909, 0.5091,\n",
      "        0.5273, 0.5455, 0.5636, 0.5818, 0.6000, 0.6182, 0.6364, 0.6545, 0.6727,\n",
      "        0.6909, 0.7091, 0.7273, 0.7455, 0.7636, 0.7818, 0.8000, 0.8182, 0.8364,\n",
      "        0.8545, 0.8727, 0.8909, 0.9091, 0.9273, 0.9455, 0.9636, 0.9818, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'lcfs_vec': tensor(0), 'lcfs_cdw_vec': tensor(0), 'lcfs_cdm_vec': tensor(0), 'dlcf_vec': tensor(0), 'dlcfs_vec': tensor(0), 'depend_vec': tensor(0), 'depended_vec': tensor(0), 'spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'text_indices': tensor([     1,   1596,  88210,  21163,    531,   4120, 126204,    443,  55332,\n",
      "           279,    262,    260,   3649,    656,   1400,   2006,    674,   1298,\n",
      "         83606,  93880, 177070,  25880,    262,    260,  14271,  58429,   2036,\n",
      "           399, 181594,  79613,    260,  85081,    268,    314,  13569,  55332,\n",
      "           279,    260,  54570,    796,    260,   2415,    260,    278, 190405,\n",
      "           278,   9059,   7470,  85727,   2216,    296, 165464,    260,    261,\n",
      "             2,   7470,  85727,   2216,    296, 165464,      2,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0]), 'aspect_bert_indices': tensor(0), 'text_raw_bert_indices': tensor(0), 'polarity': tensor(0), 'cluster_ids': tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,    0,\n",
      "           0,    0,    0,    0, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100]), 'side_ex_ids': tensor(0), 'left_lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'left_lcf_cdw_vec': tensor([0.2000, 0.2182, 0.2364, 0.2545, 0.2727, 0.2909, 0.3091, 0.3273, 0.3455,\n",
      "        0.3636, 0.3818, 0.4000, 0.4182, 0.4364, 0.4545, 0.4727, 0.4909, 0.5091,\n",
      "        0.5273, 0.5455, 0.5636, 0.5818, 0.6000, 0.6182, 0.6364, 0.6545, 0.6727,\n",
      "        0.6909, 0.7091, 0.7273, 0.7455, 0.7636, 0.7818, 0.8000, 0.8182, 0.8364,\n",
      "        0.8545, 0.8727, 0.8909, 0.9091, 0.9273, 0.9455, 0.9636, 0.9818, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'left_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'left_text_indices': tensor([     1,   1596,  88210,  21163,    531,   4120, 126204,    443,  55332,\n",
      "           279,    262,    260,   3649,    656,   1400,   2006,    674,   1298,\n",
      "         83606,  93880, 177070,  25880,    262,    260,  14271,  58429,   2036,\n",
      "           399, 181594,  79613,    260,  85081,    268,    314,  13569,  55332,\n",
      "           279,    260,  54570,    796,    260,   2415,    260,    278, 190405,\n",
      "           278,   9059,   7470,  85727,   2216,    296, 165464,    260,    261,\n",
      "             2,   7470,  85727,   2216,    296, 165464,      2,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0]), 'left_dist': tensor(0), 'right_lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'right_lcf_cdw_vec': tensor([0.2000, 0.2182, 0.2364, 0.2545, 0.2727, 0.2909, 0.3091, 0.3273, 0.3455,\n",
      "        0.3636, 0.3818, 0.4000, 0.4182, 0.4364, 0.4545, 0.4727, 0.4909, 0.5091,\n",
      "        0.5273, 0.5455, 0.5636, 0.5818, 0.6000, 0.6182, 0.6364, 0.6545, 0.6727,\n",
      "        0.6909, 0.7091, 0.7273, 0.7455, 0.7636, 0.7818, 0.8000, 0.8182, 0.8364,\n",
      "        0.8545, 0.8727, 0.8909, 0.9091, 0.9273, 0.9455, 0.9636, 0.9818, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'right_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'right_text_indices': tensor([     1,   1596,  88210,  21163,    531,   4120, 126204,    443,  55332,\n",
      "           279,    262,    260,   3649,    656,   1400,   2006,    674,   1298,\n",
      "         83606,  93880, 177070,  25880,    262,    260,  14271,  58429,   2036,\n",
      "           399, 181594,  79613,    260,  85081,    268,    314,  13569,  55332,\n",
      "           279,    260,  54570,    796,    260,   2415,    260,    278, 190405,\n",
      "           278,   9059,   7470,  85727,   2216,    296, 165464,    260,    261,\n",
      "             2,   7470,  85727,   2216,    296, 165464,      2,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0]), 'right_dist': tensor(0)}]\n",
      "2023-03-23 12:20:40,274 INFO: Load dataset from datasets/apc_datasets/101.news_german_consolidated_with_commented/news_german.valid.dat.apc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preparing dataloader: 100%|██████████| 172/172 [00:00<00:00, 1195.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-23 12:20:40,428 INFO: Dataset Label Details: {'neutral': 41, 'negative': 67, 'positive': 61, 'Sum': 169}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-23 12:20:40,508 INFO: valid data examples:\n",
      " [{'ex_id': tensor(0), 'text_raw': 'Die Gruppe fordert ein öffentliches Gespräch mit den Kanzlerkandidat*innen Armin Laschet (CDU), Olaf Scholz (SPD) und Annalena Baerbock (Grüne) noch vor der Bundestagswahl.', 'text_spc': '[CLS] Die Gruppe fordert ein öffentliches Gespräch mit den Kanzlerkandidat*innen Armin Laschet (CDU), Olaf Scholz (SPD) und Annalena Baerbock (Grüne) noch vor der Bundestagswahl. [SEP] Olaf Scholz [SEP]', 'aspect': 'Olaf Scholz', 'aspect_position': tensor(0), 'lca_ids': tensor([0.5490, 0.5686, 0.5882, 0.6078, 0.6275, 0.6471, 0.6667, 0.6863, 0.7059,\n",
      "        0.7255, 0.7451, 0.7647, 0.7843, 0.8039, 0.8235, 0.8431, 0.8627, 0.8824,\n",
      "        0.9020, 0.9216, 0.9412, 0.9608, 0.9804, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9804, 0.9608, 0.9412,\n",
      "        0.9216, 0.9020, 0.8824, 0.8627, 0.8431, 0.8235, 0.8039, 0.7843, 0.7647,\n",
      "        0.7451, 0.7255, 0.7059, 0.6863, 0.6667, 0.6471, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_vec': tensor(0), 'lcf_cdw_vec': tensor([0.5490, 0.5686, 0.5882, 0.6078, 0.6275, 0.6471, 0.6667, 0.6863, 0.7059,\n",
      "        0.7255, 0.7451, 0.7647, 0.7843, 0.8039, 0.8235, 0.8431, 0.8627, 0.8824,\n",
      "        0.9020, 0.9216, 0.9412, 0.9608, 0.9804, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9804, 0.9608, 0.9412,\n",
      "        0.9216, 0.9020, 0.8824, 0.8627, 0.8431, 0.8235, 0.8039, 0.7843, 0.7647,\n",
      "        0.7451, 0.7255, 0.7059, 0.6863, 0.6667, 0.6471, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'lcfs_vec': tensor(0), 'lcfs_cdw_vec': tensor(0), 'lcfs_cdm_vec': tensor(0), 'dlcf_vec': tensor(0), 'dlcfs_vec': tensor(0), 'depend_vec': tensor(0), 'depended_vec': tensor(0), 'spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'text_indices': tensor([     1,   1090,  67356,    260,  63369,    271,    889,    260,  62226,\n",
      "           300,  90936,    750,    531,   4228, 121359, 163918,    895,  20291,\n",
      "         17514,    349,    502,   5924,    271,    275,  94867,    507,  26164,\n",
      "           368, 125030,    361,    275, 191685,    272,    473,   7470,  85727,\n",
      "          2216,    296, 165464,    275, 228873,    272,   2815,   1498,    443,\n",
      "           260, 165566,    264,  71898,    261,      2,  26164,    368, 125030,\n",
      "           361,      2,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0]), 'aspect_bert_indices': tensor(0), 'text_raw_bert_indices': tensor(0), 'polarity': tensor(1), 'cluster_ids': tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100,    1,    1,    1,    1, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100]), 'side_ex_ids': tensor(0), 'left_lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'left_lcf_cdw_vec': tensor([0.5490, 0.5686, 0.5882, 0.6078, 0.6275, 0.6471, 0.6667, 0.6863, 0.7059,\n",
      "        0.7255, 0.7451, 0.7647, 0.7843, 0.8039, 0.8235, 0.8431, 0.8627, 0.8824,\n",
      "        0.9020, 0.9216, 0.9412, 0.9608, 0.9804, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9804, 0.9608, 0.9412,\n",
      "        0.9216, 0.9020, 0.8824, 0.8627, 0.8431, 0.8235, 0.8039, 0.7843, 0.7647,\n",
      "        0.7451, 0.7255, 0.7059, 0.6863, 0.6667, 0.6471, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'left_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'left_text_indices': tensor([     1,   1090,  67356,    260,  63369,    271,    889,    260,  62226,\n",
      "           300,  90936,    750,    531,   4228, 121359, 163918,    895,  20291,\n",
      "         17514,    349,    502,   5924,    271,    275,  94867,    507,  26164,\n",
      "           368, 125030,    361,    275, 191685,    272,    473,   7470,  85727,\n",
      "          2216,    296, 165464,    275, 228873,    272,   2815,   1498,    443,\n",
      "           260, 165566,    264,  71898,    261,      2,  26164,    368, 125030,\n",
      "           361,      2,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0]), 'left_dist': tensor(0), 'right_lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'right_lcf_cdw_vec': tensor([0.5490, 0.5686, 0.5882, 0.6078, 0.6275, 0.6471, 0.6667, 0.6863, 0.7059,\n",
      "        0.7255, 0.7451, 0.7647, 0.7843, 0.8039, 0.8235, 0.8431, 0.8627, 0.8824,\n",
      "        0.9020, 0.9216, 0.9412, 0.9608, 0.9804, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9804, 0.9608, 0.9412,\n",
      "        0.9216, 0.9020, 0.8824, 0.8627, 0.8431, 0.8235, 0.8039, 0.7843, 0.7647,\n",
      "        0.7451, 0.7255, 0.7059, 0.6863, 0.6667, 0.6471, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'right_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'right_text_indices': tensor([     1,   1090,  67356,    260,  63369,    271,    889,    260,  62226,\n",
      "           300,  90936,    750,    531,   4228, 121359, 163918,    895,  20291,\n",
      "         17514,    349,    502,   5924,    271,    275,  94867,    507,  26164,\n",
      "           368, 125030,    361,    275, 191685,    272,    473,   7470,  85727,\n",
      "          2216,    296, 165464,    275, 228873,    272,   2815,   1498,    443,\n",
      "           260, 165566,    264,  71898,    261,      2,  26164,    368, 125030,\n",
      "           361,      2,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0]), 'right_dist': tensor(0)}, {'ex_id': tensor(1), 'text_raw': 'Der begann am Freitagabend, als Armin Laschet sich zuschalten ließ in eine Programmkonferenz der CSU.', 'text_spc': '[CLS] Der begann am Freitagabend, als Armin Laschet sich zuschalten ließ in eine Programmkonferenz der CSU. [SEP] Armin Laschet [SEP]', 'aspect': 'Armin Laschet', 'aspect_position': tensor(0), 'lca_ids': tensor([0.7586, 0.7931, 0.8276, 0.8621, 0.8966, 0.9310, 0.9655, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.9655, 0.9310, 0.8966, 0.8621, 0.8276, 0.7931, 0.7586, 0.7241, 0.6897,\n",
      "        0.6552, 0.6207, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_vec': tensor(0), 'lcf_cdw_vec': tensor([0.7586, 0.7931, 0.8276, 0.8621, 0.8966, 0.9310, 0.9655, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.9655, 0.9310, 0.8966, 0.8621, 0.8276, 0.7931, 0.7586, 0.7241, 0.6897,\n",
      "        0.6552, 0.6207, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'lcfs_vec': tensor(0), 'lcfs_cdw_vec': tensor(0), 'lcfs_cdm_vec': tensor(0), 'dlcf_vec': tensor(0), 'dlcfs_vec': tensor(0), 'depend_vec': tensor(0), 'depended_vec': tensor(0), 'spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'text_indices': tensor([     1,   1684,    391,  78979,    729,    260,  68294,  49444,    262,\n",
      "          1228,  17514,    349,    502,   5924,    271,   1400,    761, 159784,\n",
      "           260, 105766,    282,   1298,  42842, 185687,    443,    260, 140051,\n",
      "           261,      2,  17514,    349,    502,   5924,    271,      2,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0]), 'aspect_bert_indices': tensor(0), 'text_raw_bert_indices': tensor(0), 'polarity': tensor(1), 'cluster_ids': tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100,    1,    1,\n",
      "           1,    1,    1, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100]), 'side_ex_ids': tensor(0), 'left_lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'left_lcf_cdw_vec': tensor([0.7586, 0.7931, 0.8276, 0.8621, 0.8966, 0.9310, 0.9655, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.9655, 0.9310, 0.8966, 0.8621, 0.8276, 0.7931, 0.7586, 0.7241, 0.6897,\n",
      "        0.6552, 0.6207, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'left_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'left_text_indices': tensor([     1,   1684,    391,  78979,    729,    260,  68294,  49444,    262,\n",
      "          1228,  17514,    349,    502,   5924,    271,   1400,    761, 159784,\n",
      "           260, 105766,    282,   1298,  42842, 185687,    443,    260, 140051,\n",
      "           261,      2,  17514,    349,    502,   5924,    271,      2,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0]), 'left_dist': tensor(0), 'right_lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'right_lcf_cdw_vec': tensor([0.7586, 0.7931, 0.8276, 0.8621, 0.8966, 0.9310, 0.9655, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.9655, 0.9310, 0.8966, 0.8621, 0.8276, 0.7931, 0.7586, 0.7241, 0.6897,\n",
      "        0.6552, 0.6207, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'right_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'right_text_indices': tensor([     1,   1684,    391,  78979,    729,    260,  68294,  49444,    262,\n",
      "          1228,  17514,    349,    502,   5924,    271,   1400,    761, 159784,\n",
      "           260, 105766,    282,   1298,  42842, 185687,    443,    260, 140051,\n",
      "           261,      2,  17514,    349,    502,   5924,    271,      2,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0]), 'right_dist': tensor(0)}]\n",
      "[2023-03-23 12:20:40] (2.0.28) \u001b[31mCaching dataset... please remove cached dataset if any problem happens.\u001b[0m\n",
      "2023-03-23 12:20:43,302 INFO: Model Architecture:\n",
      " APCEnsembler(\n",
      "  (models): ModuleList(\n",
      "    (0): FAST_LSA_T_V2(\n",
      "      (bert4global): DebertaV2Model(\n",
      "        (embeddings): DebertaV2Embeddings(\n",
      "          (word_embeddings): Embedding(251000, 768, padding_idx=0)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "          (dropout): StableDropout()\n",
      "        )\n",
      "        (encoder): DebertaV2Encoder(\n",
      "          (layer): ModuleList(\n",
      "            (0): DebertaV2Layer(\n",
      "              (attention): DebertaV2Attention(\n",
      "                (self): DisentangledSelfAttention(\n",
      "                  (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (pos_dropout): StableDropout()\n",
      "                  (dropout): StableDropout()\n",
      "                )\n",
      "                (output): DebertaV2SelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "                  (dropout): StableDropout()\n",
      "                )\n",
      "              )\n",
      "              (intermediate): DebertaV2Intermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): DebertaV2Output(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "                (dropout): StableDropout()\n",
      "              )\n",
      "            )\n",
      "            (1): DebertaV2Layer(\n",
      "              (attention): DebertaV2Attention(\n",
      "                (self): DisentangledSelfAttention(\n",
      "                  (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (pos_dropout): StableDropout()\n",
      "                  (dropout): StableDropout()\n",
      "                )\n",
      "                (output): DebertaV2SelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "                  (dropout): StableDropout()\n",
      "                )\n",
      "              )\n",
      "              (intermediate): DebertaV2Intermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): DebertaV2Output(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "                (dropout): StableDropout()\n",
      "              )\n",
      "            )\n",
      "            (2): DebertaV2Layer(\n",
      "              (attention): DebertaV2Attention(\n",
      "                (self): DisentangledSelfAttention(\n",
      "                  (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (pos_dropout): StableDropout()\n",
      "                  (dropout): StableDropout()\n",
      "                )\n",
      "                (output): DebertaV2SelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "                  (dropout): StableDropout()\n",
      "                )\n",
      "              )\n",
      "              (intermediate): DebertaV2Intermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): DebertaV2Output(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "                (dropout): StableDropout()\n",
      "              )\n",
      "            )\n",
      "            (3): DebertaV2Layer(\n",
      "              (attention): DebertaV2Attention(\n",
      "                (self): DisentangledSelfAttention(\n",
      "                  (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (pos_dropout): StableDropout()\n",
      "                  (dropout): StableDropout()\n",
      "                )\n",
      "                (output): DebertaV2SelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "                  (dropout): StableDropout()\n",
      "                )\n",
      "              )\n",
      "              (intermediate): DebertaV2Intermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): DebertaV2Output(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "                (dropout): StableDropout()\n",
      "              )\n",
      "            )\n",
      "            (4): DebertaV2Layer(\n",
      "              (attention): DebertaV2Attention(\n",
      "                (self): DisentangledSelfAttention(\n",
      "                  (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (pos_dropout): StableDropout()\n",
      "                  (dropout): StableDropout()\n",
      "                )\n",
      "                (output): DebertaV2SelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "                  (dropout): StableDropout()\n",
      "                )\n",
      "              )\n",
      "              (intermediate): DebertaV2Intermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): DebertaV2Output(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "                (dropout): StableDropout()\n",
      "              )\n",
      "            )\n",
      "            (5): DebertaV2Layer(\n",
      "              (attention): DebertaV2Attention(\n",
      "                (self): DisentangledSelfAttention(\n",
      "                  (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (pos_dropout): StableDropout()\n",
      "                  (dropout): StableDropout()\n",
      "                )\n",
      "                (output): DebertaV2SelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "                  (dropout): StableDropout()\n",
      "                )\n",
      "              )\n",
      "              (intermediate): DebertaV2Intermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): DebertaV2Output(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "                (dropout): StableDropout()\n",
      "              )\n",
      "            )\n",
      "            (6): DebertaV2Layer(\n",
      "              (attention): DebertaV2Attention(\n",
      "                (self): DisentangledSelfAttention(\n",
      "                  (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (pos_dropout): StableDropout()\n",
      "                  (dropout): StableDropout()\n",
      "                )\n",
      "                (output): DebertaV2SelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "                  (dropout): StableDropout()\n",
      "                )\n",
      "              )\n",
      "              (intermediate): DebertaV2Intermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): DebertaV2Output(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "                (dropout): StableDropout()\n",
      "              )\n",
      "            )\n",
      "            (7): DebertaV2Layer(\n",
      "              (attention): DebertaV2Attention(\n",
      "                (self): DisentangledSelfAttention(\n",
      "                  (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (pos_dropout): StableDropout()\n",
      "                  (dropout): StableDropout()\n",
      "                )\n",
      "                (output): DebertaV2SelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "                  (dropout): StableDropout()\n",
      "                )\n",
      "              )\n",
      "              (intermediate): DebertaV2Intermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): DebertaV2Output(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "                (dropout): StableDropout()\n",
      "              )\n",
      "            )\n",
      "            (8): DebertaV2Layer(\n",
      "              (attention): DebertaV2Attention(\n",
      "                (self): DisentangledSelfAttention(\n",
      "                  (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (pos_dropout): StableDropout()\n",
      "                  (dropout): StableDropout()\n",
      "                )\n",
      "                (output): DebertaV2SelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "                  (dropout): StableDropout()\n",
      "                )\n",
      "              )\n",
      "              (intermediate): DebertaV2Intermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): DebertaV2Output(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "                (dropout): StableDropout()\n",
      "              )\n",
      "            )\n",
      "            (9): DebertaV2Layer(\n",
      "              (attention): DebertaV2Attention(\n",
      "                (self): DisentangledSelfAttention(\n",
      "                  (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (pos_dropout): StableDropout()\n",
      "                  (dropout): StableDropout()\n",
      "                )\n",
      "                (output): DebertaV2SelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "                  (dropout): StableDropout()\n",
      "                )\n",
      "              )\n",
      "              (intermediate): DebertaV2Intermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): DebertaV2Output(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "                (dropout): StableDropout()\n",
      "              )\n",
      "            )\n",
      "            (10): DebertaV2Layer(\n",
      "              (attention): DebertaV2Attention(\n",
      "                (self): DisentangledSelfAttention(\n",
      "                  (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (pos_dropout): StableDropout()\n",
      "                  (dropout): StableDropout()\n",
      "                )\n",
      "                (output): DebertaV2SelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "                  (dropout): StableDropout()\n",
      "                )\n",
      "              )\n",
      "              (intermediate): DebertaV2Intermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): DebertaV2Output(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "                (dropout): StableDropout()\n",
      "              )\n",
      "            )\n",
      "            (11): DebertaV2Layer(\n",
      "              (attention): DebertaV2Attention(\n",
      "                (self): DisentangledSelfAttention(\n",
      "                  (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (pos_dropout): StableDropout()\n",
      "                  (dropout): StableDropout()\n",
      "                )\n",
      "                (output): DebertaV2SelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "                  (dropout): StableDropout()\n",
      "                )\n",
      "              )\n",
      "              (intermediate): DebertaV2Intermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): DebertaV2Output(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "                (dropout): StableDropout()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (rel_embeddings): Embedding(512, 768)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "      (post_encoder): Encoder(\n",
      "        (encoder): ModuleList(\n",
      "          (0): SelfAttention(\n",
      "            (SA): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (tanh): Tanh()\n",
      "      )\n",
      "      (post_encoder_): Encoder(\n",
      "        (encoder): ModuleList(\n",
      "          (0): SelfAttention(\n",
      "            (SA): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (tanh): Tanh()\n",
      "      )\n",
      "      (bert_pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "      (CDW_LSA): LSA(\n",
      "        (encoder): Encoder(\n",
      "          (encoder): ModuleList(\n",
      "            (0): SelfAttention(\n",
      "              (SA): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (tanh): Tanh()\n",
      "        )\n",
      "        (encoder_left): Encoder(\n",
      "          (encoder): ModuleList(\n",
      "            (0): SelfAttention(\n",
      "              (SA): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (tanh): Tanh()\n",
      "        )\n",
      "        (encoder_right): Encoder(\n",
      "          (encoder): ModuleList(\n",
      "            (0): SelfAttention(\n",
      "              (SA): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (tanh): Tanh()\n",
      "        )\n",
      "        (linear_window_3h): Linear(in_features=2304, out_features=768, bias=True)\n",
      "        (linear_window_2h): Linear(in_features=1536, out_features=768, bias=True)\n",
      "      )\n",
      "      (post_linear): Linear(in_features=1536, out_features=768, bias=True)\n",
      "      (dense): Linear(in_features=768, out_features=3, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (bert): DebertaV2Model(\n",
      "    (embeddings): DebertaV2Embeddings(\n",
      "      (word_embeddings): Embedding(251000, 768, padding_idx=0)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "      (dropout): StableDropout()\n",
      "    )\n",
      "    (encoder): DebertaV2Encoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (1): DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (2): DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (3): DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (4): DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (5): DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (6): DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (7): DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (8): DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (9): DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (10): DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (11): DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (rel_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (dense): Linear(in_features=3, out_features=3, bias=True)\n",
      ")\n",
      "2023-03-23 12:20:43,304 INFO: ABSADatasetsVersion:None\t-->\tCalling Count:0\n",
      "2023-03-23 12:20:43,304 INFO: MV:<metric_visualizer.metric_visualizer.MetricVisualizer object at 0x7f6c510ef7f0>\t-->\tCalling Count:0\n",
      "2023-03-23 12:20:43,305 INFO: PyABSAVersion:2.0.28\t-->\tCalling Count:1\n",
      "2023-03-23 12:20:43,306 INFO: SRD:3\t-->\tCalling Count:3370\n",
      "2023-03-23 12:20:43,307 INFO: TorchVersion:1.12.1+cudaNone\t-->\tCalling Count:1\n",
      "2023-03-23 12:20:43,308 INFO: TransformersVersion:4.24.0\t-->\tCalling Count:1\n",
      "2023-03-23 12:20:43,310 INFO: auto_device:True\t-->\tCalling Count:3\n",
      "2023-03-23 12:20:43,312 INFO: batch_size:16\t-->\tCalling Count:3\n",
      "2023-03-23 12:20:43,313 INFO: cache_dataset:True\t-->\tCalling Count:1\n",
      "2023-03-23 12:20:43,315 INFO: checkpoint_save_mode:1\t-->\tCalling Count:3\n",
      "2023-03-23 12:20:43,316 INFO: cross_validate_fold:-1\t-->\tCalling Count:1\n",
      "2023-03-23 12:20:43,318 INFO: dataset_file:{'train': ['datasets/apc_datasets/101.news_german_consolidated_with_commented/news_german.train.dat.apc'], 'test': ['datasets/apc_datasets/101.news_german_consolidated_with_commented/news_german.test.dat.apc'], 'valid': ['datasets/apc_datasets/101.news_german_consolidated_with_commented/news_german.valid.dat.apc']}\t-->\tCalling Count:15\n",
      "2023-03-23 12:20:43,319 INFO: dataset_name:custom_dataset\t-->\tCalling Count:1\n",
      "2023-03-23 12:20:43,320 INFO: dca_layer:3\t-->\tCalling Count:0\n",
      "2023-03-23 12:20:43,321 INFO: dca_p:1\t-->\tCalling Count:0\n",
      "2023-03-23 12:20:43,322 INFO: deep_ensemble:False\t-->\tCalling Count:0\n",
      "2023-03-23 12:20:43,323 INFO: device:cpu\t-->\tCalling Count:3\n",
      "2023-03-23 12:20:43,324 INFO: device_name:Unknown\t-->\tCalling Count:1\n",
      "2023-03-23 12:20:43,326 INFO: dlcf_a:2\t-->\tCalling Count:0\n",
      "2023-03-23 12:20:43,327 INFO: dropout:0.5\t-->\tCalling Count:1\n",
      "2023-03-23 12:20:43,329 INFO: dynamic_truncate:True\t-->\tCalling Count:3370\n",
      "2023-03-23 12:20:43,330 INFO: embed_dim:768\t-->\tCalling Count:7\n",
      "2023-03-23 12:20:43,331 INFO: eta:1\t-->\tCalling Count:2\n",
      "2023-03-23 12:20:43,334 INFO: eta_lr:0.1\t-->\tCalling Count:1\n",
      "2023-03-23 12:20:43,335 INFO: evaluate_begin:0\t-->\tCalling Count:0\n",
      "2023-03-23 12:20:43,336 INFO: from_checkpoint:None\t-->\tCalling Count:0\n",
      "2023-03-23 12:20:43,337 INFO: hidden_dim:768\t-->\tCalling Count:0\n",
      "2023-03-23 12:20:43,337 INFO: index_to_label:{0: 'negative', 1: 'neutral', 2: 'positive'}\t-->\tCalling Count:3\n",
      "2023-03-23 12:20:43,339 INFO: inference_model:None\t-->\tCalling Count:0\n",
      "2023-03-23 12:20:43,340 INFO: initializer:xavier_uniform_\t-->\tCalling Count:0\n",
      "2023-03-23 12:20:43,342 INFO: inputs_cols:['lcf_cdm_vec', 'lcf_cdw_vec', 'left_lcf_cdm_vec', 'left_lcf_cdw_vec', 'right_lcf_cdm_vec', 'right_lcf_cdw_vec', 'spc_mask_vec', 'text_indices']\t-->\tCalling Count:25281\n",
      "2023-03-23 12:20:43,343 INFO: l2reg:1e-06\t-->\tCalling Count:2\n",
      "2023-03-23 12:20:43,344 INFO: label_to_index:{'negative': 0, 'neutral': 1, 'positive': 2}\t-->\tCalling Count:0\n",
      "2023-03-23 12:20:43,354 INFO: lcf:cdw\t-->\tCalling Count:3\n",
      "2023-03-23 12:20:43,354 INFO: learning_rate:2e-05\t-->\tCalling Count:1\n",
      "2023-03-23 12:20:43,355 INFO: load_aug:False\t-->\tCalling Count:1\n",
      "2023-03-23 12:20:43,356 INFO: log_step:5\t-->\tCalling Count:0\n",
      "2023-03-23 12:20:43,357 INFO: logger:<Logger fast_lsa_t_v2 (INFO)>\t-->\tCalling Count:16\n",
      "2023-03-23 12:20:43,358 INFO: lsa:False\t-->\tCalling Count:0\n",
      "2023-03-23 12:20:43,359 INFO: max_seq_len:80\t-->\tCalling Count:20220\n",
      "2023-03-23 12:20:43,360 INFO: model:<class 'pyabsa.tasks.AspectPolarityClassification.models.__lcf__.fast_lsa_t_v2.FAST_LSA_T_V2'>\t-->\tCalling Count:4\n",
      "2023-03-23 12:20:43,361 INFO: model_name:fast_lsa_t_v2\t-->\tCalling Count:3372\n",
      "2023-03-23 12:20:43,361 INFO: model_path_to_save:/home/steffen/thesis/mv_checkpoints/\t-->\tCalling Count:0\n",
      "2023-03-23 12:20:43,362 INFO: num_epoch:20\t-->\tCalling Count:0\n",
      "2023-03-23 12:20:43,363 INFO: optimizer:adamw\t-->\tCalling Count:1\n",
      "2023-03-23 12:20:43,364 INFO: output_dim:3\t-->\tCalling Count:3\n",
      "2023-03-23 12:20:43,365 INFO: overwrite_cache:False\t-->\tCalling Count:1\n",
      "2023-03-23 12:20:43,366 INFO: path_to_save:/home/steffen/thesis/mv_checkpoints/\t-->\tCalling Count:2\n",
      "2023-03-23 12:20:43,367 INFO: patience:99999\t-->\tCalling Count:0\n",
      "2023-03-23 12:20:43,367 INFO: pretrained_bert:microsoft/mdeberta-v3-base\t-->\tCalling Count:5\n",
      "2023-03-23 12:20:43,368 INFO: save_mode:1\t-->\tCalling Count:0\n",
      "2023-03-23 12:20:43,369 INFO: seed:52\t-->\tCalling Count:7\n",
      "2023-03-23 12:20:43,370 INFO: sigma:0.3\t-->\tCalling Count:0\n",
      "2023-03-23 12:20:43,371 INFO: similarity_threshold:1\t-->\tCalling Count:3\n",
      "2023-03-23 12:20:43,372 INFO: spacy_model:de_core_news_sm\t-->\tCalling Count:6\n",
      "2023-03-23 12:20:43,373 INFO: srd_alignment:True\t-->\tCalling Count:0\n",
      "2023-03-23 12:20:43,374 INFO: task_code:APC\t-->\tCalling Count:1\n",
      "2023-03-23 12:20:43,375 INFO: task_name:Aspect-based Sentiment Classification\t-->\tCalling Count:0\n",
      "2023-03-23 12:20:43,376 INFO: tokenizer:PreTrainedTokenizerFast(name_or_path='microsoft/mdeberta-v3-base', vocab_size=250101, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\t-->\tCalling Count:0\n",
      "2023-03-23 12:20:43,377 INFO: use_amp:False\t-->\tCalling Count:1\n",
      "2023-03-23 12:20:43,378 INFO: use_bert_spc:True\t-->\tCalling Count:0\n",
      "2023-03-23 12:20:43,379 INFO: use_syntax_based_SRD:False\t-->\tCalling Count:0\n",
      "2023-03-23 12:20:43,380 INFO: warmup_step:-1\t-->\tCalling Count:0\n",
      "2023-03-23 12:20:43,381 INFO: window:lr\t-->\tCalling Count:0\n",
      "2023-03-23 12:20:43,388 INFO: ***** Running training for Aspect-based Sentiment Classification *****\n",
      "2023-03-23 12:20:43,389 INFO: Training set examples = 169\n",
      "2023-03-23 12:20:43,390 INFO: Test set examples = 1347\n",
      "2023-03-23 12:20:43,390 INFO: Total params = 291801617, Trainable params = 291801617, Non-trainable params = 0\n",
      "2023-03-23 12:20:43,391 INFO: Batch size = 16\n",
      "2023-03-23 12:20:43,392 INFO: Num steps = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Smooth Loss: 1.0695: 100%|██████████| 11/11 [02:35<00:00, 14.10s/it, Dev Acc:37.28(max:37.87) Dev F1:20.10(max:22.14)]\n",
      "Epoch:  1 | Smooth Loss: 1.0567: 100%|██████████| 11/11 [02:31<00:00, 13.73s/it, Dev Acc:38.46(max:38.46) Dev F1:25.21(max:25.21)]\n",
      "Epoch:  2 | Smooth Loss: 1.0480: 100%|██████████| 11/11 [02:31<00:00, 13.75s/it, Dev Acc:35.50(max:39.64) Dev F1:26.83(max:26.83)]\n",
      "Epoch:  3 | Smooth Loss: 1.0347: 100%|██████████| 11/11 [02:31<00:00, 13.73s/it, Dev Acc:39.05(max:39.64) Dev F1:29.45(max:29.45)]\n",
      "Epoch:  4 | Smooth Loss: 1.0213: 100%|██████████| 11/11 [03:58<00:00, 21.69s/it, Dev Acc:46.15(max:46.15) Dev F1:42.66(max:42.66)]\n",
      "Epoch:  5 | Smooth Loss: 0.9855: 100%|██████████| 11/11 [03:02<00:00, 16.59s/it, Dev Acc:43.79(max:46.75) Dev F1:42.48(max:42.66)]\n",
      "Epoch:  6 | Smooth Loss: 0.9273: 100%|██████████| 11/11 [03:27<00:00, 18.82s/it, Dev Acc:49.70(max:49.70) Dev F1:49.50(max:49.50)]\n",
      "Epoch:  7 | Smooth Loss: 0.8672: 100%|██████████| 11/11 [03:03<00:00, 16.66s/it, Dev Acc:47.93(max:49.70) Dev F1:45.40(max:49.50)]\n",
      "Epoch:  8 | Smooth Loss: 0.8100: 100%|██████████| 11/11 [03:09<00:00, 17.23s/it, Dev Acc:49.70(max:49.70) Dev F1:47.14(max:49.50)]\n",
      "Epoch:  9 | Smooth Loss: 0.7595: 100%|██████████| 11/11 [03:22<00:00, 18.41s/it, Dev Acc:52.66(max:52.66) Dev F1:50.88(max:50.88)]\n",
      "Epoch: 10 | Smooth Loss: 0.7018: 100%|██████████| 11/11 [03:39<00:00, 19.98s/it, Dev Acc:55.03(max:55.03) Dev F1:51.88(max:51.93)]\n",
      "Epoch: 11 | Smooth Loss: 0.6553: 100%|██████████| 11/11 [03:03<00:00, 16.64s/it, Dev Acc:53.85(max:55.03) Dev F1:53.23(max:53.23)]\n",
      "Epoch: 12 | Smooth Loss: 0.6153: 100%|██████████| 11/11 [03:04<00:00, 16.81s/it, Dev Acc:46.75(max:55.03) Dev F1:46.36(max:53.23)]\n",
      "Epoch: 13 | Smooth Loss: 0.5763: 100%|██████████| 11/11 [03:15<00:00, 17.75s/it, Dev Acc:57.40(max:57.40) Dev F1:55.55(max:55.55)]\n",
      "Epoch: 14 | Smooth Loss: 0.5435: 100%|██████████| 11/11 [03:43<00:00, 20.33s/it, Dev Acc:57.40(max:59.76) Dev F1:56.59(max:57.49)]\n",
      "Epoch: 15 | Smooth Loss: 0.5091: 100%|██████████| 11/11 [03:02<00:00, 16.63s/it, Dev Acc:56.21(max:59.76) Dev F1:55.14(max:57.49)]\n",
      "Epoch: 16 | Smooth Loss: 0.4803: 100%|██████████| 11/11 [03:24<00:00, 18.62s/it, Dev Acc:55.03(max:59.76) Dev F1:54.63(max:57.49)]\n",
      "Epoch: 17 | Smooth Loss: 0.4553: 100%|██████████| 11/11 [03:13<00:00, 17.55s/it, Dev Acc:57.99(max:59.76) Dev F1:57.35(max:57.49)]\n",
      "Epoch: 18 | Smooth Loss: 0.4316: 100%|██████████| 11/11 [02:52<00:00, 15.69s/it, Dev Acc:53.85(max:59.76) Dev F1:52.94(max:57.49)]\n",
      "Epoch: 19 | Smooth Loss: 0.4121: 100%|██████████| 11/11 [03:26<00:00, 18.74s/it, Dev Acc:53.85(max:59.76) Dev F1:53.26(max:57.49)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-03-23 13:23:41] (2.0.28) Loading best model: /home/steffen/thesis/mv_checkpoints//fast_lsa_t_v2_custom_dataset_acc_59.76_f1_57.49/ and evaluating on test set \n",
      "2023-03-23 13:27:42,016 INFO: \n",
      "------------------------------------------------------ Metrics Table ------------------------------------------------------\n",
      "╒═════════════════════════════════════════════════════════════╤══════════════════════════════╤═════════════════════════════╕\n",
      "│ Trial                                                       │ average-Max-Test-Acc (std)   │ average-Max-Test-F1 (std)   │\n",
      "╞═════════════════════════════════════════════════════════════╪══════════════════════════════╪═════════════════════════════╡\n",
      "│ fast_lsa_t_v2-custom_dataset-bert-base-german-dbmdz-uncased │ 61.32 (0.0)                  │ 57.99 (0.0)                 │\n",
      "├─────────────────────────────────────────────────────────────┼──────────────────────────────┼─────────────────────────────┤\n",
      "│ fast_lsa_t_v2-custom_dataset-bert-base-german-dbmdz-cased   │ 58.57 (0.0)                  │ 55.11 (0.0)                 │\n",
      "├─────────────────────────────────────────────────────────────┼──────────────────────────────┼─────────────────────────────┤\n",
      "│ fast_lsa_t_v2-custom_dataset-microsoft/mdeberta-v3-base     │ 55.53 (0.0)                  │ 52.04 (0.0)                 │\n",
      "╘═════════════════════════════════════════════════════════════╧══════════════════════════════╧═════════════════════════════╛\n",
      "------------------------------------- https://github.com/yangheng95/metric_visualizer -------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steffen/.conda/envs/thesis/lib/python3.10/site-packages/metric_visualizer/utils.py:25: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  self.skewness = stats.skew(self.data, keepdims=True)\n",
      "/home/steffen/.conda/envs/thesis/lib/python3.10/site-packages/pyabsa/framework/trainer_class/trainer_template.py:228: ResourceWarning: unclosed file <_io.TextIOWrapper name='/home/steffen/Nextcloud/uni/22-ws/thesis-personalities/code/logs/fast_lsa_t_v2_20230323 111747/trainer.log' mode='a' encoding='utf8'>\n",
      "  self.config.logger.removeHandler(self.config.logger.handlers[0])\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "config_multi = APC.APCConfigManager.get_apc_config_multilingual()\n",
    "config_multi.num_epoch = 20\n",
    "config_multi.spacy_model = \"de_core_news_sm\"\n",
    "config_multi.model = APC.APCModelList.FAST_LSA_T_V2\n",
    "\n",
    "\n",
    "config_multi.MV = config.MV\n",
    "\n",
    "trainer = APC.APCTrainer(\n",
    "    config=config_multi,\n",
    "    dataset=dataset,\n",
    "    auto_device=DeviceTypeOption.AUTO,\n",
    "    path_to_save=checkpoint_path,  # set a path to save checkpoints, if it is None, save checkpoints at 'checkpoints' folder\n",
    "    checkpoint_save_mode=ModelSaveOption.SAVE_MODEL_STATE_DICT\n",
    ")\n",
    "\n",
    "config_multi.MV.next_trial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------ Metrics Table ------------------------------------------------------\n",
      "╒═════════════════════════════════════════════════════════════╤══════════════════════════════╤═════════════════════════════╕\n",
      "│ Trial                                                       │ average-Max-Test-Acc (std)   │ average-Max-Test-F1 (std)   │\n",
      "╞═════════════════════════════════════════════════════════════╪══════════════════════════════╪═════════════════════════════╡\n",
      "│ fast_lsa_t_v2-custom_dataset-bert-base-german-dbmdz-uncased │ 61.32 (0.0)                  │ 57.99 (0.0)                 │\n",
      "├─────────────────────────────────────────────────────────────┼──────────────────────────────┼─────────────────────────────┤\n",
      "│ fast_lsa_t_v2-custom_dataset-bert-base-german-dbmdz-cased   │ 58.57 (0.0)                  │ 55.11 (0.0)                 │\n",
      "├─────────────────────────────────────────────────────────────┼──────────────────────────────┼─────────────────────────────┤\n",
      "│ fast_lsa_t_v2-custom_dataset-microsoft/mdeberta-v3-base     │ 55.53 (0.0)                  │ 52.04 (0.0)                 │\n",
      "╘═════════════════════════════════════════════════════════════╧══════════════════════════════╧═════════════════════════════╛\n",
      "------------------------------------- https://github.com/yangheng95/metric_visualizer -------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n------------------------------------------------------ Metrics Table ------------------------------------------------------\\n╒═════════════════════════════════════════════════════════════╤══════════════════════════════╤═════════════════════════════╕\\n│ Trial                                                       │ average-Max-Test-Acc (std)   │ average-Max-Test-F1 (std)   │\\n╞═════════════════════════════════════════════════════════════╪══════════════════════════════╪═════════════════════════════╡\\n│ fast_lsa_t_v2-custom_dataset-bert-base-german-dbmdz-uncased │ 61.32 (0.0)                  │ 57.99 (0.0)                 │\\n├─────────────────────────────────────────────────────────────┼──────────────────────────────┼─────────────────────────────┤\\n│ fast_lsa_t_v2-custom_dataset-bert-base-german-dbmdz-cased   │ 58.57 (0.0)                  │ 55.11 (0.0)                 │\\n├─────────────────────────────────────────────────────────────┼──────────────────────────────┼─────────────────────────────┤\\n│ fast_lsa_t_v2-custom_dataset-microsoft/mdeberta-v3-base     │ 55.53 (0.0)                  │ 52.04 (0.0)                 │\\n╘═════════════════════════════════════════════════════════════╧══════════════════════════════╧═════════════════════════════╛\\n------------------------------------- https://github.com/yangheng95/metric_visualizer -------------------------------------\\n\\nOrderedDict([('Max-Test-Acc', {'fast_lsa_t_v2-custom_dataset-bert-base-german-dbmdz-uncased': <metric_visualizer.utils.MetricList object at 0x7f6c481c6350>, 'fast_lsa_t_v2-custom_dataset-bert-base-german-dbmdz-cased': <metric_visualizer.utils.MetricList object at 0x7f6c489e9240>, 'fast_lsa_t_v2-custom_dataset-microsoft/mdeberta-v3-base': <metric_visualizer.utils.MetricList object at 0x7f6c2f977400>}), ('Max-Test-F1', {'fast_lsa_t_v2-custom_dataset-bert-base-german-dbmdz-uncased': <metric_visualizer.utils.MetricList object at 0x7f6c2d095900>, 'fast_lsa_t_v2-custom_dataset-bert-base-german-dbmdz-cased': <metric_visualizer.utils.MetricList object at 0x7f6c481c6980>, 'fast_lsa_t_v2-custom_dataset-microsoft/mdeberta-v3-base': <metric_visualizer.utils.MetricList object at 0x7f6c2f9776d0>})])\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MV.summary(save_path = \"../data/plm-trail-statistics\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
